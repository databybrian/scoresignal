{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0edc828-dc5e-4a93-8289-ff4f11d6f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, datetime\n",
    "import logging\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c5e8c-9eeb-4d48-95f5-96e5c11ae5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config together AI\n",
    "TOGETHER_API_KEY = \"87383fa10dfb16c491f9fb909a0c458ed5db1572bea1182ad941144fc16dee59\"\n",
    "\n",
    "API_URL = \"https://api.together.xyz/v1/chat/completions\"  # ‚Üê Use 'completions', NOT 'chat/completions'\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "#Config Telegram\n",
    "BOT_TOKEN = \"8388119215:AAGPOOajcj0iyha5dsWa15yzjniNwyo2QF4\" #scoresignalbot\n",
    "JSON_STORAGE_FILE = \"bot_messages.json\"\n",
    "my_chatID = [\"5759737133\"]  # yobra\n",
    "#odd api key\n",
    "# ODDS_API_KEY = \"2da01db450a92274d1b05b64f9cb8669\" # Not in use from openfootball/football.json\n",
    "# RAPID_API_KEY = \"163922200bmshb128a62208b4bf1p1ac241jsn5900dfbc6c1c\" # rapid api not sustainable $USD per month\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(\"football-api-scraper\")\n",
    "\n",
    "TODAY = str(date.today())\n",
    "os.chdir(r\"C:\\Users\\bkangethe\\Box\\Main Folder\\Analysis\\My Projects\\Data Sources\")\n",
    "OUTPUT_FILE = f\"football_odds_{TODAY}.xlsx\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a66ca9f-595a-4e7f-98e8-8cc774d17bf2",
   "metadata": {},
   "source": [
    "# open football fixtures implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10d6a9cf-9cd6-48a6-ba84-86150376f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# League key to name mapping dictionary\n",
    "\"\"\"\n",
    "Use league fixtures to confirm \"\"\"\n",
    "LEAGUE_NAMES = {\n",
    "    'at.1': 'Austrian Bundesliga',\n",
    "    'at.2': '2. Liga',\n",
    "    'be.1': 'Belgian Pro League', \n",
    "    'de.1': 'Danish Superliga',\n",
    "    'de.2': 'Danish 1st Division',\n",
    "    'en.1': 'Premier League',\n",
    "    'en.2': 'EFL Championship',\n",
    "    'en.3': 'EFL League One',\n",
    "    'en.4': 'EFL League Two',\n",
    "    'es.1': 'La Liga',\n",
    "    'es.2': 'La Liga 2',\n",
    "    'fr.1': 'Ligue 1',\n",
    "    'fr.2': 'Ligue 2',\n",
    "    'gr.1': 'Super League Greece',\n",
    "    'it.1': 'Serie A',\n",
    "    'it.2': 'Serie B',\n",
    "    'nl.1': 'Eredivisie',\n",
    "    'pt.1': 'Primeira Liga',\n",
    "    'sco.1': 'Scottish Premiership',\n",
    "    'tr.1': 'S√ºper Lig'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b58ba421-ae49-44b1-a4a5-989b4ead4217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 league files in openfootball\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('at.1', {'path': '2025-26/at.1.json', 'name': 'Austrian Bundesliga'}),\n",
       " ('at.2', {'path': '2025-26/at.2.json', 'name': '2. Liga'}),\n",
       " ('be.1', {'path': '2025-26/be.1.json', 'name': 'Belgian Pro League'})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# openfootball json fixtures\n",
    "def fetch_league_paths(season=\"2025-26\"):\n",
    "    \"\"\"\n",
    "    Fetch all available league paths for a given season from openfootball repo.\n",
    "    Returns a dict with league info {league_key: {'path': path, 'name': name}}.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.github.com/repos/openfootball/football.json/contents/{season}\"\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    files = resp.json()\n",
    "\n",
    "    league_paths = {}\n",
    "    for f in files:\n",
    "        if f[\"name\"].endswith(\".json\"):\n",
    "            league_key = f[\"name\"].replace(\".json\", \"\")  # e.g. \"en.1\"\n",
    "            league_paths[league_key] = {\n",
    "                'path': f\"{season}/{f['name']}\",\n",
    "                'name': LEAGUE_NAMES.get(league_key, f\"Unknown League ({league_key})\")\n",
    "            }\n",
    "    \n",
    "    return league_paths\n",
    "# Build global LEAGUE_PATHS dynamically\n",
    "LEAGUE_PATHS = fetch_league_paths(\"2025-26\")\n",
    "print(f\"Found {len(LEAGUE_PATHS)} league files in openfootball\")\n",
    "list(LEAGUE_PATHS.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab79541c-c4c0-485c-b9ee-84ed506d924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch fixtures openfootball\n",
    "def fetch_fixtures(league_key, season=\"2025-26\"):\n",
    "    \"\"\"\n",
    "    Fetch fixtures for one league using openfootball.\n",
    "    Args:\n",
    "        league_key: key in LEAGUE_PATHS (e.g. 'en.1')\n",
    "        season: folder (default '2025-26')\n",
    "    Returns:\n",
    "        DataFrame of fixtures with league names\n",
    "    \"\"\"\n",
    "    if league_key not in LEAGUE_PATHS:\n",
    "        raise ValueError(f\"{league_key} not found in LEAGUE_PATHS\")\n",
    "\n",
    "    url = f\"https://raw.githubusercontent.com/openfootball/football.json/master/{LEAGUE_PATHS[league_key]['path']}\"\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    fixtures = []\n",
    "    for match in data.get(\"matches\", []):\n",
    "        fixtures.append({\n",
    "            \"round\": match.get(\"round\"),\n",
    "            \"date\": match.get(\"date\"),\n",
    "            \"time\": match.get(\"time\"),\n",
    "            \"home_team\": match.get(\"team1\"),\n",
    "            \"away_team\": match.get(\"team2\"),\n",
    "            \"home_score\": match.get(\"score\", {}).get(\"ft\", [None, None])[0],\n",
    "            \"away_score\": match.get(\"score\", {}).get(\"ft\", [None, None])[1],\n",
    "            \"league_key\": league_key,\n",
    "            \"league_name\": LEAGUE_PATHS[league_key]['name'],  # Get name from LEAGUE_PATHS\n",
    "            \"season\": season\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(fixtures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5099502-32fa-4473-b287-766ef059f460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing league 3: de.1 -> {'path': '2025-26/de.1.json', 'name': 'Danish Superliga'}\n",
      "Fetched 306 fixtures\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>league_key</th>\n",
       "      <th>league_name</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>20:30</td>\n",
       "      <td>Bayern M√ºnchen</td>\n",
       "      <td>RB Leipzig</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>de.1</td>\n",
       "      <td>Danish Superliga</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>15:30</td>\n",
       "      <td>Eintracht Frankfurt</td>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>de.1</td>\n",
       "      <td>Danish Superliga</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>15:30</td>\n",
       "      <td>Bayer Leverkusen</td>\n",
       "      <td>1899 Hoffenheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>de.1</td>\n",
       "      <td>Danish Superliga</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        round        date   time            home_team        away_team  \\\n",
       "0  Matchday 1  2025-08-22  20:30       Bayern M√ºnchen       RB Leipzig   \n",
       "1  Matchday 1  2025-08-23  15:30  Eintracht Frankfurt    Werder Bremen   \n",
       "2  Matchday 1  2025-08-23  15:30     Bayer Leverkusen  1899 Hoffenheim   \n",
       "\n",
       "  home_score away_score league_key       league_name   season  \n",
       "0       None       None       de.1  Danish Superliga  2025-26  \n",
       "1       None       None       de.1  Danish Superliga  2025-26  \n",
       "2       None       None       de.1  Danish Superliga  2025-26  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick nth league (say 3rd)\n",
    "n = 3\n",
    "league_key = list(LEAGUE_PATHS.keys())[n]\n",
    "print(f\"Testing league {n}: {league_key} -> {LEAGUE_PATHS[league_key]}\")\n",
    "\n",
    "fixtures_df = fetch_fixtures(league_key)\n",
    "print(f\"Fetched {len(fixtures_df)} fixtures\")\n",
    "fixtures_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8489f0e-130a-4fac-b16a-d54c06e64ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Fixtures: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:10<00:00,  1.97league/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total fixtures collected: 6772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_fixtures = []\n",
    "failed_fixtures = []\n",
    "for league_key in tqdm(LEAGUE_PATHS.keys(), desc=\"Fetching Fixtures\", unit=\"league\"):\n",
    "    try:\n",
    "        df = fetch_fixtures(league_key, season=\"2025-26\")\n",
    "        if df is not None and len(df) > 0:\n",
    "            all_fixtures.append(df)\n",
    "        else:\n",
    "            failed_fixtures.append(league_key)\n",
    "    except Exception as e:\n",
    "        failed_fixtures.append(league_key)\n",
    "\n",
    "# Concatenate with warning suppression\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "    \n",
    "    if all_fixtures:\n",
    "        fixtures_df_all = pd.concat(all_fixtures, ignore_index=True)\n",
    "    else:\n",
    "        fixtures_df_all = pd.DataFrame()\n",
    "\n",
    "print(f\"\\nTotal fixtures collected: {len(fixtures_df_all)}\")\n",
    "\n",
    "# Display results\n",
    "if len(fixtures_df_all) > 0:   \n",
    "    fixtures_df_all.head()\n",
    "else:\n",
    "    print(\"No fixtures data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05e03e4e-71c7-4eb3-9d02-4f4a4452e9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>league_key</th>\n",
       "      <th>league_name</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>20:30</td>\n",
       "      <td>LASK</td>\n",
       "      <td>Sturm Graz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>at.1</td>\n",
       "      <td>Austrian Bundesliga</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>2025-08-02</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Wolfsberger AC</td>\n",
       "      <td>SCR Altach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>at.1</td>\n",
       "      <td>Austrian Bundesliga</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>2025-08-02</td>\n",
       "      <td>17:00</td>\n",
       "      <td>WSG Tirol</td>\n",
       "      <td>TSV Hartberg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>at.1</td>\n",
       "      <td>Austrian Bundesliga</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        round        date   time       home_team     away_team  home_score  \\\n",
       "0  Matchday 1  2025-08-01  20:30            LASK    Sturm Graz         NaN   \n",
       "1  Matchday 1  2025-08-02  17:00  Wolfsberger AC    SCR Altach         NaN   \n",
       "2  Matchday 1  2025-08-02  17:00       WSG Tirol  TSV Hartberg         NaN   \n",
       "\n",
       "   away_score league_key          league_name   season  \n",
       "0         NaN       at.1  Austrian Bundesliga  2025-26  \n",
       "1         NaN       at.1  Austrian Bundesliga  2025-26  \n",
       "2         NaN       at.1  Austrian Bundesliga  2025-26  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixtures_df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5afede56-e066-465d-87dd-669a0e050c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a6dc8-1b31-47bc-8fff-2c324606db8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d25f581-76e7-4be0-a5ae-0e9c358987e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ccd87-bbb6-40f0-a5ad-a6b81acf05bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292494a6-5939-4141-adb3-de550a8bdaca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "033e83db-7752-481b-ba7d-ce81fb1c3f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a421d81-2158-40b1-94bc-6b4844e91bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c55f4-281c-4528-995c-f425ccbacc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b0901-22f6-416e-a1cf-e4848e740225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff91d71-4a1b-4ea7-986f-6bef0d66d8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "673f5230-109b-4d08-817d-3428131e42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_odds_robust(league_name: str, api_key: str, target_dates: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch odds using the Odds API, silently and safely.\n",
    "    Only returns matches on the specified target_dates.\n",
    "\n",
    "    Returns empty DataFrame if any error occurs or no valid odds found.\n",
    "    \"\"\"\n",
    "    sport_key = LEAGUE_SPORT_KEYS.get(league_name)\n",
    "    if not sport_key:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    url = f\"https://api.the-odds-api.com/v4/sports/{sport_key}/odds/?apiKey={api_key}&regions=eu&markets=h2h&oddsFormat=decimal\"\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url)\n",
    "        resp.raise_for_status()\n",
    "        resp_json = resp.json()\n",
    "        matches_filtered = []\n",
    "\n",
    "        for game in resp_json:\n",
    "            commence_time = game.get('commence_time')\n",
    "            if not commence_time:\n",
    "                continue\n",
    "            dt = datetime.fromisoformat(commence_time.replace(\"Z\", \"+00:00\"))\n",
    "            match_date = dt.date().isoformat()\n",
    "            match_time = dt.time().strftime(\"%H:%M\")\n",
    "\n",
    "            if match_date not in target_dates:\n",
    "                continue\n",
    "\n",
    "            # Safe extraction of odds\n",
    "            try:\n",
    "                outcomes = game['bookmakers'][0]['markets'][0]['outcomes']\n",
    "                home_odds = outcomes[0]['price']\n",
    "                draw_odds = outcomes[1]['price']\n",
    "                away_odds = outcomes[2]['price']\n",
    "            except (IndexError, KeyError):\n",
    "                continue\n",
    "\n",
    "            matches_filtered.append({\n",
    "                \"league\": league_name,\n",
    "                \"date\": match_date,\n",
    "                \"time\": match_time,\n",
    "                \"home\": game['home_team'],\n",
    "                \"away\": game['away_team'],\n",
    "                \"home_odds\": home_odds,\n",
    "                \"draw_odds\": draw_odds,\n",
    "                \"away_odds\": away_odds,\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(matches_filtered)\n",
    "\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c9c431f-aafa-4a3c-ad34-69cf52311ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 15:43:14 - INFO - Fetching OpenFootball fixtures from URL: https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/be.1.json\n",
      "2025-09-22 15:43:15 - INFO - No matches today for Belgium First Div, using next matchday: 2025-09-26 (8 matches)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the unique dates from fixtures to fetch odds for\n",
    "df_fixtures = fetch_fixtures(first_league)\n",
    "fixture_dates = df_fixtures['date'].unique().tolist()\n",
    "df_odds = fetch_odds_robust( first_league, ODDS_API_KEY, fixture_dates)\n",
    "df_odds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "845d74e2-737a-41d3-84ef-8a4467c2a70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing: Primera Divisi√≥n - Argentina (sport_key: soccer_argentina_primera_division)\n",
      "üì° URL: https://api.the-odds-api.com/v4/sports/soccer_argentina_primera_division/odds/\n",
      "üìä Status Code: 401\n",
      "üìÑ Response Headers: {'Date': 'Mon, 22 Sep 2025 12:05:23 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '225', 'Connection': 'keep-alive', 'X-Requests-Used': '500', 'X-Requests-Remaining': '0', 'X-Requests-Last': '0', 'vary': 'Accept-Encoding', 'Apigw-Requestid': 'RTY8qitSoAMEZVg='}\n",
      "üìù Response Text (first 500 chars): {\"message\":\"Usage quota has been reached. See usage plans at https://the-odds-api.com\",\"error_code\":\"OUT_OF_USAGE_CREDITS\",\"details_url\":\"https://the-odds-api.com/liveapi/guides/v4/api-error-codes.html#out-of-usage-credits\"}\n",
      "...\n",
      "‚ùå API returned error: {\"message\":\"Usage quota has been reached. See usage plans at https://the-odds-api.com\",\"error_code\":\"OUT_OF_USAGE_CREDITS\",\"details_url\":\"https://the-odds-api.com/liveapi/guides/v4/api-error-codes.html#out-of-usage-credits\"}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug_fixture_fetch(league_name):\n",
    "    \"\"\"Debug function to see what's actually being returned\"\"\"\n",
    "    sport_key = LEAGUE_SPORT_KEYS.get(league_name)\n",
    "    \n",
    "    if not sport_key:\n",
    "        print(f\"‚ùå No sport key found for: {league_name}\")\n",
    "        return\n",
    "    \n",
    "    url = f\"https://api.the-odds-api.com/v4/sports/{sport_key}/odds/\"\n",
    "    params = {\n",
    "        'apiKey': ODDS_API_KEY,\n",
    "        'regions': 'us,eu,uk',\n",
    "        'markets': 'h2h',\n",
    "        'oddsFormat': 'decimal',\n",
    "        'dateFormat': 'iso'\n",
    "    }\n",
    "    \n",
    "    print(f\"üîç Testing: {league_name} (sport_key: {sport_key})\")\n",
    "    print(f\"üì° URL: {url}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        print(f\"üìä Status Code: {response.status_code}\")\n",
    "        print(f\"üìÑ Response Headers: {dict(response.headers)}\")\n",
    "        print(f\"üìù Response Text (first 500 chars): {response.text[:500]}...\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"‚úÖ JSON parsed successfully, found {len(data)} fixtures\")\n",
    "            return pd.DataFrame(data)\n",
    "        else:\n",
    "            print(f\"‚ùå API returned error: {response.text}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå JSON decode error: {e}\")\n",
    "        print(f\"üí° Response content type: {response.headers.get('content-type')}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Other error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Test with problematic league\n",
    "debug_fixture_fetch(\"Primera Divisi√≥n - Argentina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e46eed-f886-4c39-8e2c-144f810f6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixtures \n",
    "all_fixtures = []\n",
    "no_fixtures = []\n",
    "failed_fixtures = []\n",
    "\n",
    "for league in tqdm(all_leagues, desc=\"Fetching Fixtures\", ncols=80, unit=\"league\"):\n",
    "    try:\n",
    "        df = fetch_fixtures(league)\n",
    "        if df is not None and not df.empty:\n",
    "            df['league_name'] = league\n",
    "            all_fixtures.append(df)\n",
    "        else:\n",
    "            no_fixtures.append(league)  # active but no scheduled fixtures\n",
    "    except Exception:\n",
    "        failed_fixtures.append(league)  # actual error\n",
    "\n",
    "# Combine all collected fixtures\n",
    "fixtures_df = pd.concat(all_fixtures, ignore_index=True) if all_fixtures else pd.DataFrame()\n",
    "\n",
    "# --- Reporting ---\n",
    "print(f\"\\nTotal fixtures collected: {len(fixtures_df)}\")\n",
    "\n",
    "if no_fixtures:\n",
    "    print(\"No fixtures currently available for leagues:\", no_fixtures)\n",
    "\n",
    "if failed_fixtures:\n",
    "    print(\"Failed to fetch fixtures for leagues (errors):\", failed_fixtures)\n",
    "\n",
    "# Preview data\n",
    "fixtures_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76bde5-3387-4e49-9ad6-1d91374bb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All odds\n",
    "all_odds = []\n",
    "failed_odds = []\n",
    "inactive_leagues = []  # Leagues that had no fixtures (inactive)\n",
    "\n",
    "for league in tqdm(all_leagues, desc=\"Fetching Odds\", ncols=80, unit=\"league\"):\n",
    "    # Check if league failed in fixtures fetching (actual error)\n",
    "    if league in failed_fixtures:\n",
    "        failed_odds.append(league)\n",
    "        continue\n",
    "\n",
    "    # Check if league had no fixtures (inactive)\n",
    "    if league in no_fixtures:\n",
    "        inactive_leagues.append(league)\n",
    "        continue\n",
    "\n",
    "    # Extract target dates from fixtures\n",
    "    target_dates = fixtures_df.loc[fixtures_df['league_name'] == league, 'date'].dropna().unique().tolist()\n",
    "    if not target_dates:\n",
    "        inactive_leagues.append(league)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Use silent fetch_odds_robust\n",
    "        df_odds = fetch_odds_robust(league, ODDS_API_KEY, target_dates)\n",
    "        if df_odds.empty:\n",
    "            inactive_leagues.append(league)  # No odds available (treat as inactive)\n",
    "        else:\n",
    "            all_odds.append(df_odds)\n",
    "    except Exception:\n",
    "        failed_odds.append(league)  # Actual error during fetching\n",
    "\n",
    "odds_df = pd.concat(all_odds, ignore_index=True) if all_odds else pd.DataFrame()\n",
    "\n",
    "# --- Reporting ---\n",
    "print(f\"\\nTotal odds collected: {len(odds_df)}\")\n",
    "\n",
    "if inactive_leagues:\n",
    "    print(\"No odds available (inactive leagues):\", inactive_leagues)\n",
    "\n",
    "if failed_odds:\n",
    "    print(\"Failed to fetch odds (errors):\", failed_odds)\n",
    "\n",
    "# Preview data\n",
    "odds_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d128d3e-8989-4113-a8ba-2fccc95bcd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime_local column\n",
    "odds_df['datetime_local'] = pd.to_datetime(\n",
    "    odds_df['date'] + ' ' + odds_df['time'], \n",
    "    format=\"%Y-%m-%d %H:%M\",\n",
    "    errors='coerce').dt.tz_localize('UTC').dt.tz_convert('Etc/GMT-3')\n",
    "\n",
    "# Move datetime_local column immediately after time column\n",
    "time_col_index = odds_df.columns.get_loc('time')\n",
    "cols = odds_df.columns.tolist()\n",
    "cols.insert(time_col_index + 1, cols.pop(cols.index('datetime_local')))\n",
    "odds_df = odds_df[cols]\n",
    "\n",
    "# ort records by datetime_local from earliest to latest\n",
    "odds_df = odds_df.sort_values('datetime_local', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Display the result\n",
    "odds_df[['date', 'time', 'datetime_local']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e52046d2-2532-4b45-a617-602d01759697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recent_results_df(league_key: str, max_matches: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a dataframe of recent results per team, combining past seasons + current season.\n",
    "    Includes current season-to-date and up to 9 past seasons.\n",
    "    \"\"\"\n",
    "    if league_key not in LEAGUE_PATHS:\n",
    "        raise ValueError(f\"{league_key} not found in LEAGUE_PATHS\")\n",
    "    \n",
    "    current_path_info = LEAGUE_PATHS[league_key]\n",
    "    current_path = current_path_info['path']  # e.g., \"2025-26/es.1.json\"\n",
    "    league_name = current_path_info['name']   # e.g., \"La Liga\"\n",
    "    \n",
    "    season_str = current_path.split(\"/\")[0]  # e.g., \"2025-26\"\n",
    "    start_year, end_year = season_str.split(\"-\")\n",
    "\n",
    "    # Explicitly include current season first\n",
    "    season_paths = [current_path]\n",
    "\n",
    "    # Add up to 9 past seasons\n",
    "    for i in range(1, 10):\n",
    "        prev_start_year = int(start_year) - i\n",
    "        prev_end_year = prev_start_year + 1\n",
    "        prev_season_str = f\"{prev_start_year}-{prev_end_year % 100:02d}\"\n",
    "        season_path = current_path.replace(season_str, prev_season_str)\n",
    "        season_paths.append(season_path)\n",
    "\n",
    "    results = []\n",
    "    failed_urls = []\n",
    "\n",
    "    for spath in tqdm(season_paths, desc=f\"Fetching historical results for {league_name}\", ncols=120, unit=\"season\"):\n",
    "        url = f\"https://raw.githubusercontent.com/openfootball/football.json/master/{spath}\"\n",
    "        try:\n",
    "            resp = requests.get(url)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "        except Exception:\n",
    "            failed_urls.append(url)\n",
    "            continue\n",
    "\n",
    "        # Parse matches\n",
    "        for match in data.get(\"matches\", []):\n",
    "            ft_score = match.get(\"score\", {}).get(\"ft\")\n",
    "            if ft_score:\n",
    "                results.append({\n",
    "                    \"date\": match[\"date\"],\n",
    "                    \"home_team\": match[\"team1\"],\n",
    "                    \"away_team\": match[\"team2\"],\n",
    "                    \"home_score\": ft_score[0],\n",
    "                    \"away_score\": ft_score[1],\n",
    "                    \"league_key\": league_key,\n",
    "                    \"league_name\": league_name\n",
    "                })\n",
    "\n",
    "    if not results:\n",
    "        print(f\"No results found for {league_key} ({league_name})\")\n",
    "        return pd.DataFrame(columns=[\"date\", \"home_team\", \"away_team\", \"home_score\", \"away_score\", \"league_key\", \"league_name\"]), failed_urls\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results.sort_values(\"date\", ascending=False)\n",
    "\n",
    "    # Keep last max_matches per team\n",
    "    final_rows = []\n",
    "    teams = pd.unique(df_results[['home_team', 'away_team']].values.ravel())\n",
    "    for team in teams:\n",
    "        team_matches = df_results[(df_results['home_team'] == team) | (df_results['away_team'] == team)]\n",
    "        final_rows.append(team_matches.head(max_matches))\n",
    "\n",
    "    recent_results_df = pd.concat(final_rows, ignore_index=True)\n",
    "    return recent_results_df, failed_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63993fdd-e800-4d32-bd92-629ad659c460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching historical results for S√ºper Lig: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.39season/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "League Key: tr.1\n",
      "League Name: S√ºper Lig\n",
      "Current season URL: https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/tr.1.json\n",
      "Total results retrieved: 286\n",
      "Most latest results with scores: 190\n",
      "Failed URLs: ['https://raw.githubusercontent.com/openfootball/football.json/master/2023-24/tr.1.json', 'https://raw.githubusercontent.com/openfootball/football.json/master/2022-23/tr.1.json', 'https://raw.githubusercontent.com/openfootball/football.json/master/2021-22/tr.1.json', 'https://raw.githubusercontent.com/openfootball/football.json/master/2017-18/tr.1.json', 'https://raw.githubusercontent.com/openfootball/football.json/master/2016-17/tr.1.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>league_key</th>\n",
       "      <th>league_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>√áaykur Rizespor</td>\n",
       "      <td>Hatayspor</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>tr.1</td>\n",
       "      <td>S√ºper Lig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>Be≈üikta≈ü</td>\n",
       "      <td>√áaykur Rizespor</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>tr.1</td>\n",
       "      <td>S√ºper Lig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>√áaykur Rizespor</td>\n",
       "      <td>G√∂ztepe</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>tr.1</td>\n",
       "      <td>S√ºper Lig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-10</td>\n",
       "      <td>Konyaspor</td>\n",
       "      <td>√áaykur Rizespor</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>tr.1</td>\n",
       "      <td>S√ºper Lig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-03</td>\n",
       "      <td>√áaykur Rizespor</td>\n",
       "      <td>Gaziantep FK</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>tr.1</td>\n",
       "      <td>S√ºper Lig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        home_team        away_team  home_score  away_score  \\\n",
       "0  2025-05-31  √áaykur Rizespor        Hatayspor           5           2   \n",
       "1  2025-05-25         Be≈üikta≈ü  √áaykur Rizespor           1           2   \n",
       "2  2025-05-18  √áaykur Rizespor          G√∂ztepe           6           3   \n",
       "3  2025-05-10        Konyaspor  √áaykur Rizespor           2           1   \n",
       "4  2025-05-03  √áaykur Rizespor     Gaziantep FK           2           0   \n",
       "\n",
       "  league_key league_name  \n",
       "0       tr.1   S√ºper Lig  \n",
       "1       tr.1   S√ºper Lig  \n",
       "2       tr.1   S√ºper Lig  \n",
       "3       tr.1   S√ºper Lig  \n",
       "4       tr.1   S√ºper Lig  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test & confirm for a single league using the build_recent_results_df function\n",
    "recent_results_df, failed_urls = build_recent_results_df(league_key, max_matches=10)\n",
    "\n",
    "# Get league info from LEAGUE_PATHS\n",
    "league_info = LEAGUE_PATHS[league_key]\n",
    "league_name = league_info['name']  # e.g., \"Premier League\"\n",
    "current_path = league_info['path']  # e.g., \"2025-26/en.1.json\"\n",
    "\n",
    "current_url = f\"https://raw.githubusercontent.com/openfootball/football.json/master/{current_path}\"\n",
    "current_season_str = current_path.split(\"/\")[0]   # e.g., \"2025-26\"\n",
    "\n",
    "# Filter current season matches with valid scores\n",
    "current_season_results = recent_results_df[\n",
    "    recent_results_df[\"date\"].str.startswith(current_season_str[:4])\n",
    "].dropna(subset=[\"home_score\", \"away_score\"])\n",
    "\n",
    "print(f\"\\nLeague Key: {league_key}\")\n",
    "print(f\"League Name: {league_name}\")\n",
    "print(f\"Current season URL: {current_url}\")\n",
    "print(f\"Total results retrieved: {len(recent_results_df)}\")\n",
    "print(f\"Most latest results with scores: {len(current_season_results)}\")\n",
    "if len(current_season_results) == 0:\n",
    "    print(\"‚ö†Ô∏è Current season has fixtures but no recorded results yet.\")\n",
    "print(f\"Failed URLs: {failed_urls}\")\n",
    "\n",
    "recent_results_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ae908fc-56e8-41a2-b5f8-243ff97dc8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_results_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e344bf45-d994-42cd-8308-278da2d6abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching recent results for all leagues...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching historical results for Austrian Bundesliga: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:08<00:00,  1.13season/s]\n",
      "Fetching historical results for 2. Liga: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.26season/s]\n",
      "Fetching historical results for Belgian Pro League: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.38season/s]\n",
      "Fetching historical results for Danish Superliga: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.36season/s]\n",
      "Fetching historical results for Danish 1st Division: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.37season/s]\n",
      "Fetching historical results for Premier League: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.38season/s]\n",
      "Fetching historical results for EFL Championship: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.38season/s]\n",
      "Fetching historical results for EFL League One: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.39season/s]\n",
      "Fetching historical results for EFL League Two: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.35season/s]\n",
      "Fetching historical results for La Liga: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:08<00:00,  1.15season/s]\n",
      "Fetching historical results for La Liga 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.26season/s]\n",
      "Fetching historical results for Ligue 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.32season/s]\n",
      "Fetching historical results for Ligue 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.33season/s]\n",
      "Fetching historical results for Super League Greece: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.40season/s]\n",
      "Fetching historical results for Serie A: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.33season/s]\n",
      "Fetching historical results for Serie B: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.39season/s]\n",
      "Fetching historical results for Eredivisie: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.35season/s]\n",
      "Fetching historical results for Primeira Liga: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.38season/s]\n",
      "Fetching historical results for Scottish Premiership: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:07<00:00,  1.33season/s]\n",
      "Fetching historical results for S√ºper Lig: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:06<00:00,  1.65season/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recent Results Summary:\n",
      "‚úÖ Successfully processed: 20 leagues\n",
      "üìä Total matches collected: 7237\n",
      "‚ùå Failed/Skipped leagues: 0\n",
      "üîó Failed URLs: 48\n",
      "   Sample failed URLs: ['https://raw.githubusercontent.com/openfootball/football.json/master/2023-24/at.2.json', 'https://raw.githubusercontent.com/openfootball/football.json/master/2022-23/at.2.json', 'https://raw.githubusercontent.com/openfootball/football.json/master/2021-22/at.2.json']\n",
      "\n",
      "Preview: (7237, 7)\n",
      "Leagues collected:\n",
      "  - Austrian Bundesliga (at.1)\n",
      "  - 2. Liga (at.2)\n",
      "  - Belgian Pro League (be.1)\n",
      "  - Danish Superliga (de.1)\n",
      "  - Danish 1st Division (de.2)\n",
      "  - Premier League (en.1)\n",
      "  - EFL Championship (en.2)\n",
      "  - EFL League One (en.3)\n",
      "  - EFL League Two (en.4)\n",
      "  - La Liga (es.1)\n",
      "  - La Liga 2 (es.2)\n",
      "  - Ligue 1 (fr.1)\n",
      "  - Ligue 2 (fr.2)\n",
      "  - Super League Greece (gr.1)\n",
      "  - Serie A (it.1)\n",
      "  - Serie B (it.2)\n",
      "  - Eredivisie (nl.1)\n",
      "  - Primeira Liga (pt.1)\n",
      "  - Scottish Premiership (sco.1)\n",
      "  - S√ºper Lig (tr.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>league_key</th>\n",
       "      <th>league_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>LASK</td>\n",
       "      <td>Rapid Wien</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>at.1</td>\n",
       "      <td>Austrian Bundesliga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>LASK</td>\n",
       "      <td>TSV Hartberg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>at.1</td>\n",
       "      <td>Austrian Bundesliga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date home_team     away_team  home_score  away_score league_key  \\\n",
       "0  2025-05-29      LASK    Rapid Wien           3           1       at.1   \n",
       "1  2025-05-26      LASK  TSV Hartberg           2           0       at.1   \n",
       "\n",
       "           league_name  \n",
       "0  Austrian Bundesliga  \n",
       "1  Austrian Bundesliga  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_recent_results = []\n",
    "all_failed_urls = []\n",
    "failed_leagues = []\n",
    "\n",
    "print(\"Fetching recent results for all leagues...\")\n",
    "\n",
    "# Use league_keys from LEAGUE_PATHS instead of league names\n",
    "for league_key in LEAGUE_PATHS.keys():\n",
    "    try:\n",
    "        recent_df, failed_urls = build_recent_results_df(league_key, max_matches=10)\n",
    "        \n",
    "        if not recent_df.empty:\n",
    "            # The league_key and league_name are already included in the dataframe from build_recent_results_df\n",
    "            all_recent_results.append(recent_df)\n",
    "        \n",
    "        if failed_urls:\n",
    "            all_failed_urls.extend(failed_urls)\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Handle any unexpected errors\n",
    "        failed_leagues.append(league_key)\n",
    "        print(f\"Error processing {league_key}: {e}\")\n",
    "\n",
    "# Combine all leagues into a single DataFrame\n",
    "if all_recent_results:\n",
    "    recent_results_df_all = pd.concat(all_recent_results, ignore_index=True)\n",
    "else:\n",
    "    recent_results_df_all = pd.DataFrame()\n",
    "\n",
    "# --- Clean Reporting ---\n",
    "print(f\"\\nRecent Results Summary:\")\n",
    "print(f\"‚úÖ Successfully processed: {len(all_recent_results)} leagues\")\n",
    "print(f\"üìä Total matches collected: {len(recent_results_df_all)}\")\n",
    "print(f\"‚ùå Failed/Skipped leagues: {len(failed_leagues)}\")\n",
    "print(f\"üîó Failed URLs: {len(all_failed_urls)}\")\n",
    "\n",
    "if failed_leagues:\n",
    "    print(f\"   Failed/Skipped leagues: {failed_leagues}\")\n",
    "\n",
    "if all_failed_urls:\n",
    "    print(f\"   Sample failed URLs: {all_failed_urls[:3]}\")\n",
    "\n",
    "# Preview data\n",
    "if not recent_results_df_all.empty:\n",
    "    print(f\"\\nPreview: {recent_results_df_all.shape}\")\n",
    "    # Show unique leagues collected\n",
    "    unique_leagues = recent_results_df_all[['league_key', 'league_name']].drop_duplicates()\n",
    "    print(\"Leagues collected:\")\n",
    "    for _, row in unique_leagues.iterrows():\n",
    "        print(f\"  - {row['league_name']} ({row['league_key']})\")\n",
    "    \n",
    "    display(recent_results_df_all.head(2))\n",
    "else:\n",
    "    print(\"No recent results data collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521025aa-012c-4cb2-971a-d9f1bf0828fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_expert_tips_ml(odds_df: pd.DataFrame, recent_results_df_all: pd.DataFrame, \n",
    "                        strong_threshold: float = 0.15, weight_odds: float = 0.8) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enhanced expert tips with better feature engineering and model architecture\n",
    "    \"\"\"\n",
    "    # --- Enhanced Feature Engineering ---\n",
    "    hist_df = recent_results_df_all.copy()\n",
    "    hist_df['result'] = np.where(hist_df['home_score'] > hist_df['away_score'], 'home',\n",
    "                                 np.where(hist_df['home_score'] < hist_df['away_score'], 'away', 'draw'))\n",
    "    \n",
    "    # Add default odds columns to historical data since they don't exist\n",
    "    hist_df['home_odds'] = 2.0  # Default value\n",
    "    hist_df['draw_odds'] = 3.0  # Default value  \n",
    "    hist_df['away_odds'] = 2.5  # Default value\n",
    "\n",
    "    # Advanced team form calculation\n",
    "    def advanced_team_form(team, league=None, max_matches=10):\n",
    "        \"\"\"Calculate advanced form metrics with league weighting\"\"\"\n",
    "        mask = (hist_df['home_team'] == team) | (hist_df['away_team'] == team)\n",
    "        if league and 'league' in hist_df.columns:\n",
    "            mask &= (hist_df['league'] == league)\n",
    "        \n",
    "        team_results = hist_df[mask].sort_values('date', ascending=False).head(max_matches)\n",
    "        \n",
    "        if team_results.empty:\n",
    "            return {'win_rate': 0.5, 'goal_diff': 0, 'form_strength': 0.5, 'recent_goals': 1.0}\n",
    "        \n",
    "        wins, draws, losses = 0, 0, 0\n",
    "        goals_for, goals_against = 0, 0\n",
    "        \n",
    "        for _, match in team_results.iterrows():\n",
    "            if match['home_team'] == team:\n",
    "                goals_for += match['home_score']\n",
    "                goals_against += match['away_score']\n",
    "                if match['home_score'] > match['away_score']:\n",
    "                    wins += 1\n",
    "                elif match['home_score'] == match['away_score']:\n",
    "                    draws += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "            else:\n",
    "                goals_for += match['away_score']\n",
    "                goals_against += match['home_score']\n",
    "                if match['away_score'] > match['home_score']:\n",
    "                    wins += 1\n",
    "                elif match['away_score'] == match['home_score']:\n",
    "                    draws += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "        \n",
    "        total_matches = wins + draws + losses\n",
    "        win_rate = wins / total_matches if total_matches > 0 else 0.5\n",
    "        goal_diff = (goals_for - goals_against) / total_matches if total_matches > 0 else 0\n",
    "        form_strength = (wins * 1 + draws * 0.5) / total_matches if total_matches > 0 else 0.5\n",
    "        recent_goals = goals_for / total_matches if total_matches > 0 else 1.0\n",
    "        \n",
    "        return {\n",
    "            'win_rate': win_rate,\n",
    "            'goal_diff': goal_diff,\n",
    "            'form_strength': form_strength,\n",
    "            'recent_goals': recent_goals\n",
    "        }\n",
    "\n",
    "    # --- Enhanced Model Training ---\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Prepare training data with enhanced features\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for _, match in hist_df.iterrows():\n",
    "        # Use league if available, otherwise None\n",
    "        league = match.get('league') if 'league' in hist_df.columns else None\n",
    "        \n",
    "        home_form = advanced_team_form(match['home_team'], league)\n",
    "        away_form = advanced_team_form(match['away_team'], league)\n",
    "        \n",
    "        features = [\n",
    "            match['home_odds'], match['draw_odds'], match['away_odds'],\n",
    "            home_form['win_rate'], home_form['goal_diff'], home_form['form_strength'],\n",
    "            away_form['win_rate'], away_form['goal_diff'], away_form['form_strength'],\n",
    "            home_form['recent_goals'] - away_form['recent_goals']  # Goal difference trend\n",
    "        ]\n",
    "        \n",
    "        X_train.append(features)\n",
    "        y_train.append(match['result'])\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Use Gradient Boosting for better performance\n",
    "    model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, \n",
    "                                     max_depth=4, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # --- Predict on upcoming matches ---\n",
    "    df = odds_df.copy()\n",
    "    df = df.rename(columns={'home': 'home_team', 'away': 'away_team'})\n",
    "    \n",
    "    home_win_prob, draw_prob, away_win_prob, expert_tip, strong_tip = [], [], [], [], []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating Expert Tips\"):\n",
    "        home, away = row['home_team'], row['away_team']\n",
    "        h_odds, d_odds, a_odds = row['home_odds'], row['draw_odds'], row['away_odds']\n",
    "        \n",
    "        # Get league if available\n",
    "        league = row.get('league') if 'league' in df.columns else None\n",
    "        \n",
    "        # Get team form\n",
    "        home_form = advanced_team_form(home, league)\n",
    "        away_form = advanced_team_form(away, league)\n",
    "        \n",
    "        # Prepare features for prediction\n",
    "        features = [\n",
    "            h_odds, d_odds, a_odds,\n",
    "            home_form['win_rate'], home_form['goal_diff'], home_form['form_strength'],\n",
    "            away_form['win_rate'], away_form['goal_diff'], away_form['form_strength'],\n",
    "            home_form['recent_goals'] - away_form['recent_goals']\n",
    "        ]\n",
    "        \n",
    "        # Scale and predict\n",
    "        features_scaled = scaler.transform([features])\n",
    "        probs = model.predict_proba(features_scaled)[0]\n",
    "        classes = model.classes_\n",
    "        prob_dict = dict(zip(classes, probs))\n",
    "        \n",
    "        # Store probabilities\n",
    "        home_win_prob.append(prob_dict.get('home', 0))\n",
    "        draw_prob.append(prob_dict.get('draw', 0))\n",
    "        away_win_prob.append(prob_dict.get('away', 0))\n",
    "        \n",
    "        # Expert tip\n",
    "        tip = max(prob_dict, key=prob_dict.get)\n",
    "        expert_tip.append(tip)\n",
    "        \n",
    "        # Strong tip\n",
    "        sorted_probs = sorted(prob_dict.values(), reverse=True)\n",
    "        strong_tip.append(sorted_probs[0] - sorted_probs[1] >= strong_threshold)\n",
    "    \n",
    "    # Add results to DataFrame\n",
    "    df['home_win_prob'] = home_win_prob\n",
    "    df['draw_prob'] = draw_prob\n",
    "    df['away_win_prob'] = away_win_prob\n",
    "    df['expert_tip'] = expert_tip\n",
    "    df['strong_tip'] = strong_tip\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f406c05-52a4-4f47-b17a-1326404c9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_insights(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add analytical flags to enhance LLM context: favorites, value bets, tossups.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Win probability thresholds\n",
    "    df['home_win_prob_pct'] = (df['home_win_prob'] * 100).round()\n",
    "    df['draw_prob_pct'] = (df['draw_prob'] * 100).round()\n",
    "    df['away_win_prob_pct'] = (df['away_win_prob'] * 100).round()\n",
    "\n",
    "    # Team strength\n",
    "    df['is_home_favorite'] = df['home_win_prob'] > 0.55\n",
    "    df['is_away_favorite'] = df['away_win_prob'] > 0.55\n",
    "    df['is_tossup'] = (abs(df['home_win_prob'] - df['away_win_prob']) < 0.15) & (df['draw_prob'] < 0.35)\n",
    "\n",
    "    # Value betting flags\n",
    "    df['has_high_draw_odds'] = df['draw_odds'] > 3.4\n",
    "    df['home_good_value'] = (df['home_odds'] >= 2.4) & (df['home_win_prob'] > 0.4)\n",
    "    df['away_underdog_value'] = (df['away_odds'] >= 3.0) & (df['away_win_prob'] > 0.3)\n",
    "\n",
    "    # Strong tip (from earlier logic)\n",
    "    df['strong_ml_tip'] = df['strong_tip']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89afe0-084f-40d9-a267-c803483e133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in notebook\n",
    "df_with_tips = fetch_expert_tips_ml(odds_df, recent_results_df_all, strong_threshold=0.2)\n",
    "df_enriched = enrich_with_insights(df_with_tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eab6bb-96ee-47a1-8007-93c38458df99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_enhanced_prompt(row) -> str:\n",
    "    \"\"\"\n",
    "    Build a rich, contextual prompt for the LLM using ML + odds insights.\n",
    "    \"\"\"\n",
    "    home, away = row['home_team'], row['away_team']\n",
    "    league = row.get('league', 'a league')\n",
    "\n",
    "    # Probabilities as percentages\n",
    "    h_prob = row['home_win_prob']\n",
    "    d_prob = row['draw_prob']\n",
    "    a_prob = row['away_win_prob']\n",
    "\n",
    "    # --- Momentum & Dominance ---\n",
    "    if h_prob > 0.6:\n",
    "        momentum = f\"{home} are strong favorites based on form and consistent performance.\"\n",
    "    elif a_prob > 0.6:\n",
    "        momentum = f\"{away} appear superior on paper and should dominate despite being away.\"\n",
    "    elif abs(h_prob - a_prob) < 0.15:\n",
    "        momentum = \"This is a tightly contested match between evenly matched teams.\"\n",
    "    else:\n",
    "        momentum = f\"{home} hold a slight edge at home, but {away} have shown resilience recently.\"\n",
    "\n",
    "    # --- Value Detection ---\n",
    "    value_lines = []\n",
    "    if row['has_high_draw_odds'] and d_prob > 0.28:\n",
    "        value_lines.append(f\"The draw at {row['draw_odds']} offers solid value given its {d_prob:.0%} likelihood.\")\n",
    "    if row['home_good_value']:\n",
    "        value_lines.append(f\"{home} at {row['home_odds']} represents promising value against the odds.\")\n",
    "    if row['away_underdog_value']:\n",
    "        value_lines.append(f\"{away} could be a smart longshot play at {row['away_odds']}.\")\n",
    "    \n",
    "    value_tip = \" \".join(value_lines) if value_lines else \"\"\n",
    "\n",
    "    # --- Expert Tip Context ---\n",
    "    expert_call = row['expert_tip'].upper()\n",
    "    if expert_call == 'HOME':\n",
    "        expert_reason = f\"{home} are favored by both model and market.\"\n",
    "    elif expert_call == 'AWAY':\n",
    "        expert_reason = f\"{away} are backed by strong away-form metrics.\"\n",
    "    elif expert_call == 'DRAW':\n",
    "        expert_reason = f\"The model sees this as a tactical stalemate with high draw probability.\"\n",
    "    else:\n",
    "        expert_reason = f\"This match lacks a clear favorite according to analytics.\"\n",
    "\n",
    "    # --- Final Prompt ---\n",
    "    prompt = f\"\"\"\n",
    "You are a top-tier football betting analyst writing for a premium tips platform.\n",
    "Write a **confident, concise 1‚Äì2 sentence summary** predicting the outcome of this match.\n",
    "\n",
    "Guidelines:\n",
    "- Be authoritative and specific. No disclaimers like \"unpredictable\" or \"can go either way\".\n",
    "- Mention team strength, momentum, or value in the odds.\n",
    "- Use active language: \"will\", \"should\", \"look set to\".\n",
    "- NEVER hedge. ALWAYS pick a side unless the draw is strongly supported.\n",
    "\n",
    "Match: {home} vs {away}\n",
    "League: {league}\n",
    "Odds (H/D/A): {row['home_odds']} / {row['draw_odds']} / {row['away_odds']}\n",
    "Win Probabilities: {h_prob:.0%} / {d_prob:.0%} / {a_prob:.0%}\n",
    "Expert Tip: {expert_call}\n",
    "\n",
    "Context:\n",
    "{momentum}\n",
    "{value_tip}\n",
    "{expert_reason}\n",
    "\n",
    "Now write the final summary:\n",
    "\"\"\"\n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325509a-2e10-43ec-ae7c-f32cdb65f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_generic(text: str) -> bool:\n",
    "    if not text or len(text.strip()) < 5:\n",
    "        return True\n",
    "    text_lower = text.lower()\n",
    "    bad_phrases = ['unpredictable', 'hard to call', 'either way', 'no clear favorite', \n",
    "                   'could go either way', 'uncertain', 'caution', 'avoid']\n",
    "    return any(phrase in text_lower for phrase in bad_phrases)\n",
    "\n",
    "def fallback_summary(row):\n",
    "    tip = row['expert_tip'].upper()\n",
    "    if tip == 'HOME':\n",
    "        return f\"{row['home_team']} are favored based on form and odds.\"\n",
    "    elif tip == 'AWAY':\n",
    "        return f\"{row['away_team']} holds an edge on the road.\"\n",
    "    elif tip == 'DRAW':\n",
    "        return f\"Model suggests a draw; consider value at current odds.\"\n",
    "    else:\n",
    "        return f\"Match analysis shows no strong lean.\"\n",
    "\n",
    "def refine_with_fallback(row, original=\"\"):\n",
    "    tip = row['expert_tip']\n",
    "    h, a = row['home_team'], row['away_team']\n",
    "    if tip == 'home':\n",
    "        return f\"{h} should edge this contest based on superior form and home advantage.\"\n",
    "    elif tip == 'away':\n",
    "        return f\"{a} looks capable of snatching three points despite being away.\"\n",
    "    elif tip == 'draw':\n",
    "        return f\"Expect a tight tactical battle ending in a draw.\"\n",
    "    else:\n",
    "        return f\"{h} vs {a}: too close to call, slight nod to home side.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe5873-712a-4f18-9815-e65a1ae74512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Your API (Together AI Example) ---\n",
    "def add_llm_summaries(\n",
    "    odds_df: pd.DataFrame,\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    api_url=\"https://api.together.xyz/v1/chat/completions\",  # ‚Üê Using chat endpoint\n",
    "    headers=HEADERS,\n",
    "    max_retries=3,\n",
    "    delay_per_call=0.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate LLM summaries with clean progress tracking and proper response handling.\n",
    "    Uses chat/completions ‚Üí parses 'message.content'.\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "\n",
    "    # Single progress bar with clear updates\n",
    "    for _, row in tqdm(odds_df.iterrows(), total=len(odds_df), desc=\"üß† Generating Expert Summaries\", unit=\"match\"):\n",
    "        summary_text = \"\"\n",
    "\n",
    "        try:\n",
    "            prompt = build_enhanced_prompt(row)\n",
    "        except Exception as e:\n",
    "            print(f\"Prompt build failed for {row['home_team']} vs {row['away_team']}: {e}\")\n",
    "            summary_text = fallback_summary(row)\n",
    "            summaries.append(summary_text)\n",
    "            time.sleep(delay_per_call)\n",
    "            continue\n",
    "\n",
    "        success = False\n",
    "        for attempt in range(max_retries + 1):\n",
    "            try:\n",
    "                payload = {\n",
    "                    \"model\": model_name,\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    \"max_tokens\": 90,\n",
    "                    \"temperature\": 0.3,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"repetition_penalty\": 1.05,\n",
    "                    \"stop\": [\"\\n\\n\", \"Match:\", \"League:\", \"User:\", \"Assistant:\"]\n",
    "                }\n",
    "\n",
    "                response = requests.post(api_url, headers=headers, json=payload, timeout=30)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    \n",
    "                    # ‚úÖ Correct key for /chat/completions\n",
    "                    content = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                    \n",
    "                    # Clean up: take only first 1‚Äì2 sentences\n",
    "                    sentences = [s.strip() for s in content.split('. ') if s.strip()]\n",
    "                    summary_text = '. '.join(sentences[:2]) + '.' if sentences else fallback_summary(row)\n",
    "                    \n",
    "                    success = True\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"‚ùå HTTP {response.status_code} on attempt {attempt + 1}: {response.text[:100]}...\")\n",
    "                    time.sleep(2 ** attempt)  # Exponential backoff\n",
    "\n",
    "            except KeyError as e:\n",
    "                print(f\"üîë Parse error (missing key {e}) - retrying...\")\n",
    "                time.sleep(1.5)\n",
    "            except Exception as e:\n",
    "                if attempt >= max_retries:\n",
    "                    print(f\"üõë Failed after retries: {row['home_team']} vs {row['away_team']} | Error: {e}\")\n",
    "                else:\n",
    "                    time.sleep(2 ** attempt)\n",
    "\n",
    "        if not success:\n",
    "            summary_text = fallback_summary(row)\n",
    "\n",
    "        # Final quality filter\n",
    "        if is_generic(summary_text):\n",
    "            summary_text = refine_with_fallback(row, summary_text)\n",
    "\n",
    "        summaries.append(summary_text)\n",
    "        time.sleep(delay_per_call)\n",
    "\n",
    "    # Add to DataFrame\n",
    "    result_df = odds_df.copy()\n",
    "    result_df['tip_summary'] = summaries\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0522869-dc28-416d-a278-02eebbc49ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = build_enhanced_prompt(df_enriched.iloc[0])\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": test_prompt}],\n",
    "    \"max_tokens\": 90,\n",
    "    \"temperature\": 0.3,\n",
    "    \"top_p\": 0.9,\n",
    "    \"repetition_penalty\": 1.05,\n",
    "    \"stop\": [\"\\n\\n\", \"Match:\", \"User:\", \"Assistant:\"]\n",
    "}\n",
    "\n",
    "resp = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "print(\"Status:\", resp.status_code)\n",
    "if resp.status_code == 200:\n",
    "    print(\"Success:\\n\", resp.json()[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "else:\n",
    "    print(\"Error:\\n\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de29973-ac0c-4c5c-a463-ea049266e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow\n",
    "df_tips = fetch_expert_tips_ml(odds_df, recent_results_df_all, strong_threshold=0.2)\n",
    "df_enriched = enrich_with_insights(df_tips)\n",
    "df_final = add_llm_summaries(df_enriched, delay_per_call=0.5)\n",
    "df_final['tip_source'] = df_final['strong_tip'].map({True: 'strong_ml', False: 'weak_ml'})\n",
    "cols = [\n",
    "    'home_team', 'away_team', 'league',\n",
    "    'home_odds', 'draw_odds', 'away_odds',\n",
    "    'home_win_prob', 'draw_prob', 'away_win_prob',\n",
    "    'expert_tip', 'strong_tip', 'tip_source',  # if you added ensemble earlier\n",
    "    'tip_summary'\n",
    "]\n",
    "\n",
    "display(df_final[cols].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8de941-43f7-4fb3-9a7f-3ce837ea843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove timezone info from all DataFrames before saving to Excel\n",
    "def remove_timezone_from_df(df):\n",
    "    \"\"\"Remove timezone info from datetime columns in a DataFrame\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return df\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            df[col] = df[col].dt.tz_localize(None)  # Remove timezone info\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4074da-b975-4845-9deb-039aa0f3b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File configuration\n",
    "TODAY = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "OUTPUT_FILE = f\"football_data_{TODAY}.xlsx\"\n",
    "\n",
    "# Create a dictionary of all DataFrames to clean\n",
    "dataframes_to_clean = {\n",
    "    \"Fixtures\": fixtures_df,\n",
    "    \"Odds\": odds_df,\n",
    "    \"Recent Results\": recent_results_df_all,\n",
    "    \"Expert Tips\": df_enriched,\n",
    "    \"LLM Summaries\": df_final\n",
    "}\n",
    "\n",
    "# Clean all DataFrames in one go using dictionary comprehension\n",
    "cleaned_dataframes = {\n",
    "    sheet_name: remove_timezone_from_df(df.copy()) \n",
    "    for sheet_name, df in dataframes_to_clean.items()\n",
    "}\n",
    "\n",
    "# Create main metadata DataFrame\n",
    "metadata = {\n",
    "    \"Generated On\": [datetime.now().replace(tzinfo=None)],\n",
    "    \"Leagues Included\": [\", \".join(all_leagues)],\n",
    "    \"Total Fixtures\": [len(fixtures_df)],\n",
    "    \"Total Odds\": [len(odds_df)],\n",
    "    \"Total Recent Results\": [len(recent_results_df_all)],\n",
    "    \"Total Matches with Tips\": [len(df_final)],\n",
    "    \"Total Matches with LLM Summaries\": [len(df_final)]\n",
    "}\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "\n",
    "# Create soccer keys DataFrame\n",
    "if not df_soccer.empty:\n",
    "    soccer_keys_list = [f\"{row['key']} ({row['title']})\" for _, row in df_soccer.iterrows()]\n",
    "else:\n",
    "    soccer_keys_list = [\"No soccer keys data\"]\n",
    "\n",
    "soccer_keys_df = pd.DataFrame({\n",
    "    \"Available Soccer Keys\": soccer_keys_list\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "with pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\") as writer:\n",
    "    # Write main DataFrames\n",
    "    for sheet_name, df_clean in cleaned_dataframes.items():\n",
    "        df_clean.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    \n",
    "    # Write metadata section\n",
    "    metadata_df.to_excel(writer, sheet_name=\"Metadata\", index=False)\n",
    "    \n",
    "    # Write soccer keys section with empty row separation\n",
    "    start_row = len(metadata_df) + 2  # +2 for header row and one empty row\n",
    "    soccer_keys_df.to_excel(writer, sheet_name=\"Metadata\", index=False, \n",
    "                          startrow=start_row, header=True)\n",
    "\n",
    "print(f\"All data saved successfully to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e37f39a2-57cf-4564-9633-ed5085922de4",
   "metadata": {},
   "source": [
    "Telegram Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce935a7-f3fd-49c0-8af2-e69f3fd3dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong tips within the next 48 hours\n",
    "def filter_strong_tips(df_final: pd.DataFrame, max_hours_ahead=48) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter strong ML tips where:\n",
    "    - tip_source == 'strong_ml'\n",
    "    - match has not started\n",
    "    - match starts within the next 2 days (48 hours)\n",
    "    Returns cleaned DataFrame with odds and formatted time.\n",
    "    \"\"\"\n",
    "    # Step 1: Filter strong tips\n",
    "    if df_final.empty:\n",
    "        return df_final\n",
    "\n",
    "    strong_mask = df_final['tip_source'] == 'strong_ml'\n",
    "    strong_tips_df = df_final[strong_mask].copy()\n",
    "    \n",
    "    if strong_tips_df.empty:\n",
    "        return strong_tips_df\n",
    "\n",
    "    # Ensure datetime column exists and is datetime type\n",
    "    if 'datetime_local' not in strong_tips_df.columns:\n",
    "        raise KeyError(\"Column 'datetime_local' not found in DataFrame.\")\n",
    "        \n",
    "    if not pd.api.types.is_datetime64_any_dtype(strong_tips_df['datetime_local']):\n",
    "        raise TypeError(\"Column 'datetime_local' must be a datetime type.\")\n",
    "\n",
    "    # Remove timezone if present (ensure naive)\n",
    "    if strong_tips_df['datetime_local'].dt.tz is not None:\n",
    "        print(\"Removing timezone info from datetime_local...\")\n",
    "        dt_local = strong_tips_df['datetime_local'].dt.tz_localize(None)\n",
    "    else:\n",
    "        dt_local = strong_tips_df['datetime_local']\n",
    "\n",
    "    # Use Africa/Nairobi as reference time context\n",
    "    try:\n",
    "        now_naive = pd.Timestamp.now(tz='Africa/Nairobi').tz_localize(None)\n",
    "    except Exception:\n",
    "        print(\"Warning: Fallback to system time.\")\n",
    "        now_naive = pd.Timestamp.now()\n",
    "\n",
    "    # Define time window: now to now + 2 days\n",
    "    two_days_ahead = now_naive + pd.Timedelta(days=2)\n",
    "\n",
    "    # Create mask: match hasn't started AND is within next 2 days\n",
    "    upcoming_mask = (dt_local > now_naive) & (dt_local <= two_days_ahead)\n",
    "    upcoming_tips_df = strong_tips_df[upcoming_mask].copy()\n",
    "\n",
    "    if upcoming_tips_df.empty:\n",
    "        return upcoming_tips_df\n",
    "\n",
    "    # Column mapping for output\n",
    "    column_mapping = {\n",
    "        'league': 'league',\n",
    "        'datetime_local': 'datetime_local',\n",
    "        'home_team': 'home',\n",
    "        'away_team': 'away',\n",
    "        'home_odds': 'home_odds',\n",
    "        'draw_odds': 'draw_odds',\n",
    "        'away_odds': 'away_odds',\n",
    "        'expert_tip': 'expert_tip',\n",
    "        'tip_summary': 'tip_summary'\n",
    "    }\n",
    "\n",
    "    missing_cols = [col for col in column_mapping.keys() if col not in upcoming_tips_df.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "    result = upcoming_tips_df[list(column_mapping.keys())].rename(columns=column_mapping)\n",
    "\n",
    "    # Format datetime as string for display\n",
    "    result['datetime_local'] = result['datetime_local'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859db17-4faa-4dbe-9b0c-85aafc94cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage message history\n",
    "def load_message_history(storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"Load message history from JSON file\"\"\"\n",
    "    try:\n",
    "        with open(storage_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return {}\n",
    "\n",
    "def save_message_history(history, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"Save message history to JSON file\"\"\"\n",
    "    with open(storage_file, 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "\n",
    "def track_message(chat_id, message_id, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"Track a message ID for a specific chat in persistent storage\"\"\"\n",
    "    history = load_message_history(storage_file)\n",
    "    \n",
    "    if str(chat_id) not in history:\n",
    "        history[str(chat_id)] = []\n",
    "    \n",
    "    # Add new message ID and keep only unique IDs\n",
    "    if message_id not in history[str(chat_id)]:\n",
    "        history[str(chat_id)].append(message_id)\n",
    "    \n",
    "    # Optional: Limit to last 200 messages per chat to avoid file bloat\n",
    "    history[str(chat_id)] = history[str(chat_id)][-200:]\n",
    "    \n",
    "    save_message_history(history, storage_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7183f-c73d-43a2-86af-2ed8f44858ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send messages\n",
    "def send_telegram_message(message, chat_ids, bot_token, track_message_id=True, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"\n",
    "    Helper function to send a single Telegram message with optional tracking\n",
    "    \n",
    "    Parameters:\n",
    "    message (str): The message to send\n",
    "    chat_ids (list): List of chat IDs to send to\n",
    "    bot_token (str): Bot token\n",
    "    track_message_id (bool): Whether to track the message ID for later deletion\n",
    "    storage_file (str): Path to the JSON storage file\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if at least one message was sent successfully\n",
    "    \"\"\"\n",
    "    success_count = 0\n",
    "    \n",
    "    for chat_id in chat_ids:\n",
    "        try:\n",
    "            url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "            payload = {\n",
    "                'chat_id': chat_id,\n",
    "                'text': message,\n",
    "                'parse_mode': 'Markdown',\n",
    "                'disable_web_page_preview': True\n",
    "            }\n",
    "            \n",
    "            response = requests.post(url, data=payload)\n",
    "            if response.status_code == 200:\n",
    "                success_count += 1\n",
    "                \n",
    "                # Track the message ID if requested\n",
    "                if track_message_id:\n",
    "                    message_id = response.json()['result']['message_id']\n",
    "                    track_message(chat_id, message_id, storage_file)\n",
    "                    \n",
    "            else:\n",
    "                print(f\"‚ùå Failed to send message to {chat_id}: {response.text}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error sending message to {chat_id}: {e}\")\n",
    "    \n",
    "    return success_count > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62384f0-9a71-4e42-a090-17a2e58ad152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send strong tips\n",
    "def send_strong_tips_telegram_multiple_users(strong_tips_df, chat_ids, bot_token, track_messages=True, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"\n",
    "    Send strong tips to multiple Telegram users with message chunking and tracking\n",
    "    \n",
    "    Parameters:\n",
    "    strong_tips_df (DataFrame): DataFrame with strong tips data\n",
    "    chat_ids (list): List of chat IDs to send to\n",
    "    bot_token (str): Bot token\n",
    "    track_messages (bool): Whether to track message IDs for later deletion\n",
    "    storage_file (str): Path to the JSON storage file\n",
    "    \n",
    "    Returns:\n",
    "    int: Total number of successful message sends\n",
    "    \"\"\"\n",
    "    if strong_tips_df.empty:\n",
    "        message = \"‚öΩ No strong tips found today! ‚öΩ\"\n",
    "        send_count = 1 if send_telegram_message(message, chat_ids, bot_token, track_messages, storage_file) else 0\n",
    "        return send_count\n",
    "    \n",
    "    total_success_count = 0\n",
    "    \n",
    "    for chat_id in chat_ids:\n",
    "        chat_success_count = 0\n",
    "        \n",
    "        try:\n",
    "            # Create message header\n",
    "            header = f\"‚öΩ *STRONG BETTING TIPS* ‚öΩ\\n\\n\"\n",
    "            header += f\"Found {len(strong_tips_df)} matches with strong tips:\\n\\n\"\n",
    "            \n",
    "            # ‚úÖ Add payment information\n",
    "            header += \"üîê *For advanced modelling tips, support via MPESA:* \\n\"\n",
    "            header += \"üìå *TILL: 9105695*\\n\"\n",
    "            header += \"üì± *Mobile:* +254722586447\\n\\n\"  # Replace 07XXXXXX with actual number\n",
    "            header += \"Thank you for your support! üíô\\n\\n\"\n",
    "            \n",
    "            # Send header first\n",
    "            if send_telegram_message(header, [chat_id], bot_token, track_messages, storage_file):\n",
    "                chat_success_count += 1\n",
    "            \n",
    "            # Send each match as separate message\n",
    "            for _, row in strong_tips_df.iterrows():\n",
    "                match_message = f\"üèÜ *{row['league']}*\\n\"\n",
    "                match_message += f\"‚è∞ {row['datetime_local']}\\n\"\n",
    "                match_message += f\"üè† {row['home']} vs {row['away']}\\n\"\n",
    "                \n",
    "                # ‚úÖ Correctly show decimal odds\n",
    "                match_message += f\"üî¢ Odds: {row['home_odds']:.2f} | {row['draw_odds']:.2f} | {row['away_odds']:.2f}\\n\"\n",
    "                \n",
    "                # Show expert tip\n",
    "                tip_emoji = \"üü¢ HOME\" if row['expert_tip'] == 'home' else \\\n",
    "                           (\"üü° DRAW\" if row['expert_tip'] == 'draw' else \"üîµ AWAY\")\n",
    "                match_message += f\"üí° Tip: {tip_emoji} ({row['expert_tip'].upper()})\\n\"\n",
    "                \n",
    "                # Truncate summary if too long\n",
    "                summary = str(row['tip_summary'])\n",
    "                if len(summary) > 200:\n",
    "                    match_message += f\"üìù Summary: {summary[:200]}...\\n\"\n",
    "                else:\n",
    "                    match_message += f\"üìù Summary: {summary}\\n\"\n",
    "                \n",
    "                match_message += \"‚îÄ\" * 30\n",
    "                \n",
    "                # Send individual match message\n",
    "                if send_telegram_message(match_message, [chat_id], bot_token, track_messages, storage_file):\n",
    "                    chat_success_count += 1\n",
    "            \n",
    "            print(f\"‚úÖ {chat_success_count} messages sent to chat ID: {chat_id}\")\n",
    "            total_success_count += chat_success_count\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error sending to {chat_id}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìä Summary: Total messages sent: {total_success_count}\")\n",
    "    return total_success_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee750507-f597-433e-8ff3-9226c62097e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get chat IDS\n",
    "def get_chat_ids(bot_token):\n",
    "    \"\"\"Get all chat IDs that have interacted with your bot\"\"\"\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/getUpdates\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            chat_ids = set()\n",
    "            \n",
    "            for update in data.get('result', []):\n",
    "                if 'message' in update and 'chat' in update['message']:\n",
    "                    chat_ids.add(update['message']['chat']['id'])\n",
    "            \n",
    "            print(\"Found chat IDs:\", list(chat_ids))\n",
    "            return list(chat_ids)\n",
    "        else:\n",
    "            print(\"Error getting updates:\", response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return []\n",
    "\n",
    "def clear_bot_messages(chat_id=None, bot_token=BOT_TOKEN, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"\n",
    "    Clear all tracked bot messages for a specific chat or all chats.\n",
    "    \n",
    "    Parameters:\n",
    "    chat_id (int/str): Specific chat ID to clear. If None, clears all chats.\n",
    "    bot_token (str): Bot token to use for deletion\n",
    "    storage_file (str): Path to the JSON storage file\n",
    "    \"\"\"\n",
    "    history = load_message_history(storage_file)\n",
    "    \n",
    "    if not history:\n",
    "        print(\"No message history found to clear.\")\n",
    "        return 0\n",
    "    \n",
    "    chats_to_clear = [str(chat_id)] if chat_id else list(history.keys())\n",
    "    total_deleted = 0\n",
    "    \n",
    "    for current_chat_id in chats_to_clear:\n",
    "        if current_chat_id not in history:\n",
    "            print(f\"Chat ID {current_chat_id} not found in history.\")\n",
    "            continue\n",
    "            \n",
    "        message_ids = history[current_chat_id]\n",
    "        deleted_in_chat = 0\n",
    "        \n",
    "        print(f\"\\nClearing {len(message_ids)} messages in chat {current_chat_id}...\")\n",
    "        \n",
    "        for msg_id in message_ids:\n",
    "            url = f\"https://api.telegram.org/bot{bot_token}/deleteMessage\"\n",
    "            payload = {\n",
    "                'chat_id': current_chat_id,\n",
    "                'message_id': msg_id\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.post(url, data=payload)\n",
    "                if response.status_code == 200:\n",
    "                    deleted_in_chat += 1\n",
    "                    total_deleted += 1\n",
    "                    print(f\"‚úì Deleted message {msg_id}\")\n",
    "                else:\n",
    "                    print(f\"‚úó Failed to delete {msg_id}: {response.text}\")\n",
    "                \n",
    "                # Add a small delay to avoid hitting rate limits\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚úó Error deleting {msg_id}: {e}\")\n",
    "        \n",
    "        # Clear the history for this chat after successful deletion\n",
    "        history[current_chat_id] = []\n",
    "        print(f\"Cleared {deleted_in_chat} messages from chat {current_chat_id}\")\n",
    "    \n",
    "    # Save the updated history (with cleared chats)\n",
    "    save_message_history(history, storage_file)\n",
    "    print(f\"\\nüéâ Total messages deleted: {total_deleted}\")\n",
    "    return total_deleted\n",
    "\n",
    "def show_message_stats(storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"Show statistics about tracked messages\"\"\"\n",
    "    history = load_message_history(storage_file)\n",
    "    total_messages = 0\n",
    "    \n",
    "    print(\"üìä Message Tracking Statistics:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for chat_id, messages in history.items():\n",
    "        print(f\"Chat {chat_id}: {len(messages)} messages\")\n",
    "        total_messages += len(messages)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total chats: {len(history)}\")\n",
    "    print(f\"Total messages: {total_messages}\")\n",
    "    return len(history), total_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286dcf6-0c43-4cd6-941a-a23f5042b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting chat IDs...\")\n",
    "chat_ids = get_chat_ids(BOT_TOKEN)\n",
    "\n",
    "# Print the number of participants\n",
    "if chat_ids:\n",
    "    print(f\"‚úÖ Number of participants: {len(chat_ids)}\")\n",
    "else:\n",
    "    print(\"‚ùå No participants found. Chat ID list is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debef94a-95ad-4f01-8d60-245092eee155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the strong tips\n",
    "df_final = remove_timezone_from_df(df_final) \n",
    "strong_tips_filtered = filter_strong_tips(df_final, max_hours_ahead=48)  # 2-day lookahead\n",
    "print(\"\\nSending strong tips with tracking...\")\n",
    "send_count = send_strong_tips_telegram_multiple_users(\n",
    "    strong_tips_filtered, \n",
    "    chat_ids, \n",
    "    BOT_TOKEN,\n",
    "    track_messages=True  # Set to False if you don't want to track these messages\n",
    ")\n",
    "print(f\"Sent {send_count} messages\")\n",
    "\n",
    "# Show current message statistics\n",
    "print(\"\\nCurrent stats:\")\n",
    "show_message_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190af9a0-df2b-4a4b-a6e0-65271e567d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing messages\n",
    "# Clear messages from a specific chat\n",
    "# clear_bot_messages(chat_id=123456789, bot_token=BOT_TOKEN)\n",
    "\n",
    "# Clear messages from ALL chats (use with caution!)\n",
    "#print(\"\\nClearing all messages...\")\n",
    "#deleted_count = clear_bot_messages(bot_token=BOT_TOKEN)\n",
    "#print(f\"Deleted {deleted_count} messages\")\n",
    "\n",
    "# Send a message without tracking (for one-time notifications)\n",
    "# send_telegram_message(\"This message won't be tracked\", chat_ids, BOT_TOKEN, track_message_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d40f6-9516-40c8-9d03-43dccd845de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
