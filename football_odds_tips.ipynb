{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0edc828-dc5e-4a93-8289-ff4f11d6f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, datetime\n",
    "import logging\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c5e8c-9eeb-4d48-95f5-96e5c11ae5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config together AI\n",
    "TOGETHER_API_KEY = \"87383fa10dfb16c491f9fb909a0c458ed5db1572bea1182ad941144fc16dee59\"\n",
    "\n",
    "API_URL = \"https://api.together.xyz/v1/chat/completions\"  # ← Use 'completions', NOT 'chat/completions'\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "#Config Telegram\n",
    "BOT_TOKEN = \"8388119215:AAGPOOajcj0iyha5dsWa15yzjniNwyo2QF4\" #scoresignalbot\n",
    "JSON_STORAGE_FILE = \"bot_messages.json\"\n",
    "my_chatID = [\"5759737133\"]  # yobra\n",
    "#odd api key\n",
    "# ODDS_API_KEY = \"2da01db450a92274d1b05b64f9cb8669\" # Not in use from openfootball/football.json\n",
    "# RAPID_API_KEY = \"163922200bmshb128a62208b4bf1p1ac241jsn5900dfbc6c1c\" # rapid api not sustainable $USD per month\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(\"football-api-scraper\")\n",
    "\n",
    "TODAY = str(date.today())\n",
    "os.chdir(r\"C:\\Users\\bkangethe\\Box\\Main Folder\\Analysis\\My Projects\\Data Sources\")\n",
    "OUTPUT_FILE = f\"football_odds_{TODAY}.xlsx\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a66ca9f-595a-4e7f-98e8-8cc774d17bf2",
   "metadata": {},
   "source": [
    "# open football fixtures implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f1a592-448b-4629-b5ce-99219683ca07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 valid league mappings from 23 total rows\n",
      "\n",
      "League paths from openfootball: 16\n",
      "Leagues missing odds mappings: set()\n",
      "\n",
      "All leagues in LEAGUE_PATHS:\n",
      "be.1: Belgian Pro League\n",
      "en.1: Premier League\n",
      "en.2: EFL Championship\n",
      "en.3: EFL League One\n",
      "en.4: EFL League Two\n",
      "es.1: La Liga\n",
      "es.2: La Liga 2\n",
      "fr.1: Ligue 1\n",
      "fr.2: Ligue 2\n",
      "gr.1: Super League Greece\n",
      "it.1: Serie A\n",
      "it.2: Serie B\n",
      "nl.1: Eredivisie\n",
      "pt.1: Primeira Liga\n",
      "sco.1: Scottish Premiership\n",
      "tr.1: Süper Lig\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from league_data import LEAGUE_NAMES, LEAGUE_PATHS\n",
    "print(f\"\\nLeague paths from openfootball: {len(LEAGUE_PATHS)}\")\n",
    "# See which leagues are in LEAGUE_PATHS but not in LEAGUE_NAMES\n",
    "missing_mappings = set(LEAGUE_PATHS.keys()) - set(LEAGUE_NAMES.keys())\n",
    "print(f\"Leagues missing odds mappings: {missing_mappings}\")\n",
    "\n",
    "# See the actual names in LEAGUE_PATHS\n",
    "print(\"\\nAll leagues in LEAGUE_PATHS:\")\n",
    "for key, info in LEAGUE_PATHS.items():\n",
    "    print(f\"{key}: {info['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "406e905e-3701-42ee-97f9-066ea4e4c1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at.1 (Unknown League (at.1)): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/at.1.json\n",
      "at.2 (Unknown League (at.2)): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/at.2.json\n",
      "be.1 (Belgian Pro League): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/be.1.json\n",
      "de.1 (Unknown League (de.1)): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/de.1.json\n",
      "de.2 (Unknown League (de.2)): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/de.2.json\n",
      "en.1 (Premier League): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/en.1.json\n",
      "en.2 (EFL Championship): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/en.2.json\n",
      "en.3 (EFL League One): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/en.3.json\n",
      "en.4 (EFL League Two): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/en.4.json\n",
      "es.1 (La Liga): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/es.1.json\n",
      "es.2 (La Liga 2): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/es.2.json\n",
      "fr.1 (Ligue 1): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/fr.1.json\n",
      "fr.2 (Ligue 2): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/fr.2.json\n",
      "gr.1 (Super League Greece): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/gr.1.json\n",
      "it.1 (Serie A): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/it.1.json\n",
      "it.2 (Serie B): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/it.2.json\n",
      "nl.1 (Eredivisie): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/nl.1.json\n",
      "pt.1 (Primeira Liga): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/pt.1.json\n",
      "sco.1 (Scottish Premiership): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/sco.1.json\n",
      "tr.1 (Süper Lig): https://raw.githubusercontent.com/openfootball/football.json/master/2025-26/tr.1.json\n"
     ]
    }
   ],
   "source": [
    "from league_data import get_league_paths\n",
    "# Get all league paths\n",
    "league_paths = get_league_paths(\"2025-26\")\n",
    "\n",
    "# Generate actual GitHub raw URLs for each league\n",
    "base_url = \"https://raw.githubusercontent.com/openfootball/football.json/master/\"\n",
    "\n",
    "for league_key, info in league_paths.items():\n",
    "    actual_url = base_url + info['path']\n",
    "    print(f\"{league_key} ({info['name']}): {actual_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af56f4a3-e36d-4daf-819e-b3beb7a4c2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 5788 fixtures from local CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>Date</th>\n",
       "      <th>time</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>league_key</th>\n",
       "      <th>league_name</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>7/25/2025</td>\n",
       "      <td>20:45</td>\n",
       "      <td>Royal Antwerp FC</td>\n",
       "      <td>Union Saint-Gilloise</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>be.1</td>\n",
       "      <td>Belgian Pro League</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>7/26/2025</td>\n",
       "      <td>16:00</td>\n",
       "      <td>FCV Dender EH</td>\n",
       "      <td>Cercle Brugge</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>be.1</td>\n",
       "      <td>Belgian Pro League</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>7/26/2025</td>\n",
       "      <td>18:15</td>\n",
       "      <td>SV Zulte Waregem</td>\n",
       "      <td>KV Mechelen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>be.1</td>\n",
       "      <td>Belgian Pro League</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>7/26/2025</td>\n",
       "      <td>20:45</td>\n",
       "      <td>RAA La Louviére</td>\n",
       "      <td>Standard Liège</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>be.1</td>\n",
       "      <td>Belgian Pro League</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matchday 1</td>\n",
       "      <td>7/27/2025</td>\n",
       "      <td>13:30</td>\n",
       "      <td>RSC Anderlecht</td>\n",
       "      <td>KVC Westerlo</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>be.1</td>\n",
       "      <td>Belgian Pro League</td>\n",
       "      <td>2025-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        round       Date   time         home_team             away_team  \\\n",
       "0  Matchday 1  7/25/2025  20:45  Royal Antwerp FC  Union Saint-Gilloise   \n",
       "1  Matchday 1  7/26/2025  16:00     FCV Dender EH         Cercle Brugge   \n",
       "2  Matchday 1  7/26/2025  18:15  SV Zulte Waregem           KV Mechelen   \n",
       "3  Matchday 1  7/26/2025  20:45   RAA La Louviére        Standard Liège   \n",
       "4  Matchday 1  7/27/2025  13:30    RSC Anderlecht          KVC Westerlo   \n",
       "\n",
       "   home_score  away_score league_key         league_name   season  \n",
       "0         1.0         1.0       be.1  Belgian Pro League  2025-26  \n",
       "1         0.0         0.0       be.1  Belgian Pro League  2025-26  \n",
       "2         1.0         1.0       be.1  Belgian Pro League  2025-26  \n",
       "3         0.0         2.0       be.1  Belgian Pro League  2025-26  \n",
       "4         5.0         2.0       be.1  Belgian Pro League  2025-26  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_fixture_data import load_fixtures\n",
    "fixtures_df = load_fixtures()  # This loads your fixtures.csv file\n",
    "print(f\"✅ Loaded {len(fixtures_df)} fixtures from local CSV\")\n",
    "# Cell 3: Explore your data (this is where you do your analysis)\n",
    "fixtures_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce89fcc3-abb8-4912-9122-c3b64d739cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 valid league mappings from 23 total rows\n",
      "✅ Successfully loaded 16 league mappings\n",
      "Found 26 leagues for 2023-24 season:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from league_data import fetch_league_paths\n",
    "leagues = fetch_league_paths(\"2024-25\")\n",
    "print(f\"Found {len(leagues)} leagues for 2023-24 season:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51e314b-1c6d-482f-829a-0e82b471591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           home_team            away_team\n",
      "0       Gaziantep FK          Galatasaray\n",
      "1         Samsunspor       Gençlerbirliği\n",
      "2        Antalyaspor         Kasımpaşa SK\n",
      "3         Fenerbahçe           Alanyaspor\n",
      "4           Eyüpspor            Konyaspor\n",
      "5    Çaykur Rizespor              Göztepe\n",
      "6   Fatih Karagümrük  İstanbul Başakşehir\n",
      "7        Kayserispor             Beşiktaş\n",
      "8        Trabzonspor          Kocaelispor\n",
      "9        Galatasaray     Fatih Karagümrük\n",
      "10       Kocaelispor           Samsunspor\n",
      "11        Alanyaspor      Çaykur Rizespor\n"
     ]
    }
   ],
   "source": [
    "# Test fetching\n",
    "from fetch_fixtures_live import fetch_fixtures\n",
    "# Try a league with special characters\n",
    "df = fetch_fixtures('tr.1')  # Belgian league has many special characters\n",
    "print(df[['home_team', 'away_team']].head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8129d431-5e7f-41b6-86dd-93aa817d67bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All fixture teams have mappings!\n"
     ]
    }
   ],
   "source": [
    "# In your main pipeline\n",
    "from load_fixture_data import load_fixtures\n",
    "from data_utils import validate_team_mapping\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "fixtures_df = load_fixtures()\n",
    "mapping_df = pd.read_csv(\"team_mapping.csv\")  # or however you load it\n",
    "\n",
    "# Validate mappings\n",
    "unmapped = validate_team_mapping(fixtures_df, mapping_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e9f461-8301-4dea-b3cf-457d0a21ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 103,535\n",
      "Date range: 1/1/2011 to 9/9/2024\n",
      "Leagues: ['E2' 'E3' 'E0' 'SC0' 'E1' 'F1' 'F2' 'D2' 'N1' 'P1' 'T1' 'I2' 'B1' 'SP2'\n",
      " 'D1' 'I1' 'SC1' 'G1' 'SP1']\n",
      "Teams: 726 unique teams\n",
      "Bet365 coverage: 99.8% of matches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkangethe\\AppData\\Local\\Temp\\ipykernel_18760\\2805102608.py:3: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"cleaned_historical_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_historical_data.csv\")\n",
    "print(f\"Total matches: {len(df):,}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"Leagues: {df['league_code'].unique()}\")\n",
    "print(f\"Teams: {df['HomeTeam'].nunique()} unique teams\")\n",
    "print(f\"Bet365 coverage: {df['B365H'].notna().mean():.1%} of matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d25f581-76e7-4be0-a5ae-0e9c358987e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Data Quality Check:\n",
      "Matches with missing results: 0\n",
      "Matches with missing Bet365 odds: 235\n",
      "Top leagues: {'E1': 8351, 'E3': 8275, 'E2': 8231, 'SP2': 6996, 'I2': 6358}\n"
     ]
    }
   ],
   "source": [
    "from load_clean_historical_data import load_clean_historical_data\n",
    "modelling_df = load_clean_historical_data()\n",
    "print(\"\\n🔍 Data Quality Check:\")\n",
    "print(f\"Matches with missing results: {(modelling_df['FTHG'].isna() | modelling_df['FTAG'].isna()).sum()}\")\n",
    "print(f\"Matches with missing Bet365 odds: {modelling_df['B365H'].isna().sum()}\")\n",
    "print(f\"Top leagues: {modelling_df['league_code'].value_counts().head(5).to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36ccd87-bbb6-40f0-a5ad-a6b81acf05bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'result': {'url': 'https://unhasted-clotty-shaunta.ngrok-free.dev/webhook', 'has_custom_certificate': False, 'pending_update_count': 3, 'last_error_date': 1759006839, 'last_error_message': 'Wrong response from the webhook: 404 Not Found', 'max_connections': 40, 'ip_address': '3.124.142.205'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "TOKEN = \"8388119215:AAGPOOajcj0iyha5dsWa15yzjniNwyo2QF4\"\n",
    "WEBHOOK_URL = \"https://your-web-service.up.railway.app/webhook\"\n",
    "response = requests.get(f\"https://api.telegram.org/bot{TOKEN}/getWebhookInfo\")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50c55f4-281c-4528-995c-f425ccbacc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': False, 'error_code': 404, 'description': 'Not Found'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BOT_TOKEN = \"8388119215:AAGPOOajcj0iyha5dsWa15yzjniNwyo2QF4\"\n",
    "WEBHOOK_URL = \"https://your-webhook-service.up.railway.app/webhook\"\n",
    "\n",
    "# Set webhook\n",
    "response = requests.get(f\"https://api.telegram.org/bot{BOT_TOKEN}/setWebhook?url={WEBHOOK_URL}\")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c7d2c2-e891-4bf1-ac34-fe21ea29749b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [400]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "requests.post(\"https://scoresignalbot-production.up.railway.app/webhook\", json={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395ede38-46cf-4c10-ab91-f9489c6eb8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [400]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.post(\"https://scoresignalbot-production.up.railway.app/webhook\", json={})  # ← This sends valid empty JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b09b0901-22f6-416e-a1cf-e4848e740225",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1547347324.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python -c \"from src.league_data import LEAGUE_PATHS; print(f'Leagues: {len(LEAGUE_PATHS)}')\"\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -c \"from src.league_data import LEAGUE_PATHS; print(f'Leagues: {len(LEAGUE_PATHS)}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09df3c97-c776-489d-8a0b-d27884b03ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(f\"https://api.telegram.org/bot{\"8388119215:AAGPOOajcj0iyha5dsWa15yzjniNwyo2QF4\"}/setWebhook?url={WEBHOOK_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e7527-79e6-4c32-b388-f127a469d273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff91d71-4a1b-4ea7-986f-6bef0d66d8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521025aa-012c-4cb2-971a-d9f1bf0828fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_expert_tips_ml(odds_df: pd.DataFrame, recent_results_df_all: pd.DataFrame, \n",
    "                        strong_threshold: float = 0.15, weight_odds: float = 0.8) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enhanced expert tips with better feature engineering and model architecture\n",
    "    \"\"\"\n",
    "    # --- Enhanced Feature Engineering ---\n",
    "    hist_df = recent_results_df_all.copy()\n",
    "    hist_df['result'] = np.where(hist_df['home_score'] > hist_df['away_score'], 'home',\n",
    "                                 np.where(hist_df['home_score'] < hist_df['away_score'], 'away', 'draw'))\n",
    "    \n",
    "    # Add default odds columns to historical data since they don't exist\n",
    "    hist_df['home_odds'] = 2.0  # Default value\n",
    "    hist_df['draw_odds'] = 3.0  # Default value  \n",
    "    hist_df['away_odds'] = 2.5  # Default value\n",
    "\n",
    "    # Advanced team form calculation\n",
    "    def advanced_team_form(team, league=None, max_matches=10):\n",
    "        \"\"\"Calculate advanced form metrics with league weighting\"\"\"\n",
    "        mask = (hist_df['home_team'] == team) | (hist_df['away_team'] == team)\n",
    "        if league and 'league' in hist_df.columns:\n",
    "            mask &= (hist_df['league'] == league)\n",
    "        \n",
    "        team_results = hist_df[mask].sort_values('date', ascending=False).head(max_matches)\n",
    "        \n",
    "        if team_results.empty:\n",
    "            return {'win_rate': 0.5, 'goal_diff': 0, 'form_strength': 0.5, 'recent_goals': 1.0}\n",
    "        \n",
    "        wins, draws, losses = 0, 0, 0\n",
    "        goals_for, goals_against = 0, 0\n",
    "        \n",
    "        for _, match in team_results.iterrows():\n",
    "            if match['home_team'] == team:\n",
    "                goals_for += match['home_score']\n",
    "                goals_against += match['away_score']\n",
    "                if match['home_score'] > match['away_score']:\n",
    "                    wins += 1\n",
    "                elif match['home_score'] == match['away_score']:\n",
    "                    draws += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "            else:\n",
    "                goals_for += match['away_score']\n",
    "                goals_against += match['home_score']\n",
    "                if match['away_score'] > match['home_score']:\n",
    "                    wins += 1\n",
    "                elif match['away_score'] == match['home_score']:\n",
    "                    draws += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "        \n",
    "        total_matches = wins + draws + losses\n",
    "        win_rate = wins / total_matches if total_matches > 0 else 0.5\n",
    "        goal_diff = (goals_for - goals_against) / total_matches if total_matches > 0 else 0\n",
    "        form_strength = (wins * 1 + draws * 0.5) / total_matches if total_matches > 0 else 0.5\n",
    "        recent_goals = goals_for / total_matches if total_matches > 0 else 1.0\n",
    "        \n",
    "        return {\n",
    "            'win_rate': win_rate,\n",
    "            'goal_diff': goal_diff,\n",
    "            'form_strength': form_strength,\n",
    "            'recent_goals': recent_goals\n",
    "        }\n",
    "\n",
    "    # --- Enhanced Model Training ---\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Prepare training data with enhanced features\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    for _, match in hist_df.iterrows():\n",
    "        # Use league if available, otherwise None\n",
    "        league = match.get('league') if 'league' in hist_df.columns else None\n",
    "        \n",
    "        home_form = advanced_team_form(match['home_team'], league)\n",
    "        away_form = advanced_team_form(match['away_team'], league)\n",
    "        \n",
    "        features = [\n",
    "            match['home_odds'], match['draw_odds'], match['away_odds'],\n",
    "            home_form['win_rate'], home_form['goal_diff'], home_form['form_strength'],\n",
    "            away_form['win_rate'], away_form['goal_diff'], away_form['form_strength'],\n",
    "            home_form['recent_goals'] - away_form['recent_goals']  # Goal difference trend\n",
    "        ]\n",
    "        \n",
    "        X_train.append(features)\n",
    "        y_train.append(match['result'])\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Use Gradient Boosting for better performance\n",
    "    model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, \n",
    "                                     max_depth=4, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # --- Predict on upcoming matches ---\n",
    "    df = odds_df.copy()\n",
    "    df = df.rename(columns={'home': 'home_team', 'away': 'away_team'})\n",
    "    \n",
    "    home_win_prob, draw_prob, away_win_prob, expert_tip, strong_tip = [], [], [], [], []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating Expert Tips\"):\n",
    "        home, away = row['home_team'], row['away_team']\n",
    "        h_odds, d_odds, a_odds = row['home_odds'], row['draw_odds'], row['away_odds']\n",
    "        \n",
    "        # Get league if available\n",
    "        league = row.get('league') if 'league' in df.columns else None\n",
    "        \n",
    "        # Get team form\n",
    "        home_form = advanced_team_form(home, league)\n",
    "        away_form = advanced_team_form(away, league)\n",
    "        \n",
    "        # Prepare features for prediction\n",
    "        features = [\n",
    "            h_odds, d_odds, a_odds,\n",
    "            home_form['win_rate'], home_form['goal_diff'], home_form['form_strength'],\n",
    "            away_form['win_rate'], away_form['goal_diff'], away_form['form_strength'],\n",
    "            home_form['recent_goals'] - away_form['recent_goals']\n",
    "        ]\n",
    "        \n",
    "        # Scale and predict\n",
    "        features_scaled = scaler.transform([features])\n",
    "        probs = model.predict_proba(features_scaled)[0]\n",
    "        classes = model.classes_\n",
    "        prob_dict = dict(zip(classes, probs))\n",
    "        \n",
    "        # Store probabilities\n",
    "        home_win_prob.append(prob_dict.get('home', 0))\n",
    "        draw_prob.append(prob_dict.get('draw', 0))\n",
    "        away_win_prob.append(prob_dict.get('away', 0))\n",
    "        \n",
    "        # Expert tip\n",
    "        tip = max(prob_dict, key=prob_dict.get)\n",
    "        expert_tip.append(tip)\n",
    "        \n",
    "        # Strong tip\n",
    "        sorted_probs = sorted(prob_dict.values(), reverse=True)\n",
    "        strong_tip.append(sorted_probs[0] - sorted_probs[1] >= strong_threshold)\n",
    "    \n",
    "    # Add results to DataFrame\n",
    "    df['home_win_prob'] = home_win_prob\n",
    "    df['draw_prob'] = draw_prob\n",
    "    df['away_win_prob'] = away_win_prob\n",
    "    df['expert_tip'] = expert_tip\n",
    "    df['strong_tip'] = strong_tip\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f406c05-52a4-4f47-b17a-1326404c9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_insights(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add analytical flags to enhance LLM context: favorites, value bets, tossups.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Win probability thresholds\n",
    "    df['home_win_prob_pct'] = (df['home_win_prob'] * 100).round()\n",
    "    df['draw_prob_pct'] = (df['draw_prob'] * 100).round()\n",
    "    df['away_win_prob_pct'] = (df['away_win_prob'] * 100).round()\n",
    "\n",
    "    # Team strength\n",
    "    df['is_home_favorite'] = df['home_win_prob'] > 0.55\n",
    "    df['is_away_favorite'] = df['away_win_prob'] > 0.55\n",
    "    df['is_tossup'] = (abs(df['home_win_prob'] - df['away_win_prob']) < 0.15) & (df['draw_prob'] < 0.35)\n",
    "\n",
    "    # Value betting flags\n",
    "    df['has_high_draw_odds'] = df['draw_odds'] > 3.4\n",
    "    df['home_good_value'] = (df['home_odds'] >= 2.4) & (df['home_win_prob'] > 0.4)\n",
    "    df['away_underdog_value'] = (df['away_odds'] >= 3.0) & (df['away_win_prob'] > 0.3)\n",
    "\n",
    "    # Strong tip (from earlier logic)\n",
    "    df['strong_ml_tip'] = df['strong_tip']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89afe0-084f-40d9-a267-c803483e133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in notebook\n",
    "df_with_tips = fetch_expert_tips_ml(odds_df, recent_results_df_all, strong_threshold=0.2)\n",
    "df_enriched = enrich_with_insights(df_with_tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eab6bb-96ee-47a1-8007-93c38458df99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_enhanced_prompt(row) -> str:\n",
    "    \"\"\"\n",
    "    Build a rich, contextual prompt for the LLM using ML + odds insights.\n",
    "    \"\"\"\n",
    "    home, away = row['home_team'], row['away_team']\n",
    "    league = row.get('league', 'a league')\n",
    "\n",
    "    # Probabilities as percentages\n",
    "    h_prob = row['home_win_prob']\n",
    "    d_prob = row['draw_prob']\n",
    "    a_prob = row['away_win_prob']\n",
    "\n",
    "    # --- Momentum & Dominance ---\n",
    "    if h_prob > 0.6:\n",
    "        momentum = f\"{home} are strong favorites based on form and consistent performance.\"\n",
    "    elif a_prob > 0.6:\n",
    "        momentum = f\"{away} appear superior on paper and should dominate despite being away.\"\n",
    "    elif abs(h_prob - a_prob) < 0.15:\n",
    "        momentum = \"This is a tightly contested match between evenly matched teams.\"\n",
    "    else:\n",
    "        momentum = f\"{home} hold a slight edge at home, but {away} have shown resilience recently.\"\n",
    "\n",
    "    # --- Value Detection ---\n",
    "    value_lines = []\n",
    "    if row['has_high_draw_odds'] and d_prob > 0.28:\n",
    "        value_lines.append(f\"The draw at {row['draw_odds']} offers solid value given its {d_prob:.0%} likelihood.\")\n",
    "    if row['home_good_value']:\n",
    "        value_lines.append(f\"{home} at {row['home_odds']} represents promising value against the odds.\")\n",
    "    if row['away_underdog_value']:\n",
    "        value_lines.append(f\"{away} could be a smart longshot play at {row['away_odds']}.\")\n",
    "    \n",
    "    value_tip = \" \".join(value_lines) if value_lines else \"\"\n",
    "\n",
    "    # --- Expert Tip Context ---\n",
    "    expert_call = row['expert_tip'].upper()\n",
    "    if expert_call == 'HOME':\n",
    "        expert_reason = f\"{home} are favored by both model and market.\"\n",
    "    elif expert_call == 'AWAY':\n",
    "        expert_reason = f\"{away} are backed by strong away-form metrics.\"\n",
    "    elif expert_call == 'DRAW':\n",
    "        expert_reason = f\"The model sees this as a tactical stalemate with high draw probability.\"\n",
    "    else:\n",
    "        expert_reason = f\"This match lacks a clear favorite according to analytics.\"\n",
    "\n",
    "    # --- Final Prompt ---\n",
    "    prompt = f\"\"\"\n",
    "You are a top-tier football betting analyst writing for a premium tips platform.\n",
    "Write a **confident, concise 1–2 sentence summary** predicting the outcome of this match.\n",
    "\n",
    "Guidelines:\n",
    "- Be authoritative and specific. No disclaimers like \"unpredictable\" or \"can go either way\".\n",
    "- Mention team strength, momentum, or value in the odds.\n",
    "- Use active language: \"will\", \"should\", \"look set to\".\n",
    "- NEVER hedge. ALWAYS pick a side unless the draw is strongly supported.\n",
    "\n",
    "Match: {home} vs {away}\n",
    "League: {league}\n",
    "Odds (H/D/A): {row['home_odds']} / {row['draw_odds']} / {row['away_odds']}\n",
    "Win Probabilities: {h_prob:.0%} / {d_prob:.0%} / {a_prob:.0%}\n",
    "Expert Tip: {expert_call}\n",
    "\n",
    "Context:\n",
    "{momentum}\n",
    "{value_tip}\n",
    "{expert_reason}\n",
    "\n",
    "Now write the final summary:\n",
    "\"\"\"\n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325509a-2e10-43ec-ae7c-f32cdb65f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_generic(text: str) -> bool:\n",
    "    if not text or len(text.strip()) < 5:\n",
    "        return True\n",
    "    text_lower = text.lower()\n",
    "    bad_phrases = ['unpredictable', 'hard to call', 'either way', 'no clear favorite', \n",
    "                   'could go either way', 'uncertain', 'caution', 'avoid']\n",
    "    return any(phrase in text_lower for phrase in bad_phrases)\n",
    "\n",
    "def fallback_summary(row):\n",
    "    tip = row['expert_tip'].upper()\n",
    "    if tip == 'HOME':\n",
    "        return f\"{row['home_team']} are favored based on form and odds.\"\n",
    "    elif tip == 'AWAY':\n",
    "        return f\"{row['away_team']} holds an edge on the road.\"\n",
    "    elif tip == 'DRAW':\n",
    "        return f\"Model suggests a draw; consider value at current odds.\"\n",
    "    else:\n",
    "        return f\"Match analysis shows no strong lean.\"\n",
    "\n",
    "def refine_with_fallback(row, original=\"\"):\n",
    "    tip = row['expert_tip']\n",
    "    h, a = row['home_team'], row['away_team']\n",
    "    if tip == 'home':\n",
    "        return f\"{h} should edge this contest based on superior form and home advantage.\"\n",
    "    elif tip == 'away':\n",
    "        return f\"{a} looks capable of snatching three points despite being away.\"\n",
    "    elif tip == 'draw':\n",
    "        return f\"Expect a tight tactical battle ending in a draw.\"\n",
    "    else:\n",
    "        return f\"{h} vs {a}: too close to call, slight nod to home side.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe5873-712a-4f18-9815-e65a1ae74512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Your API (Together AI Example) ---\n",
    "def add_llm_summaries(\n",
    "    odds_df: pd.DataFrame,\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    api_url=\"https://api.together.xyz/v1/chat/completions\",  # ← Using chat endpoint\n",
    "    headers=HEADERS,\n",
    "    max_retries=3,\n",
    "    delay_per_call=0.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate LLM summaries with clean progress tracking and proper response handling.\n",
    "    Uses chat/completions → parses 'message.content'.\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "\n",
    "    # Single progress bar with clear updates\n",
    "    for _, row in tqdm(odds_df.iterrows(), total=len(odds_df), desc=\"🧠 Generating Expert Summaries\", unit=\"match\"):\n",
    "        summary_text = \"\"\n",
    "\n",
    "        try:\n",
    "            prompt = build_enhanced_prompt(row)\n",
    "        except Exception as e:\n",
    "            print(f\"Prompt build failed for {row['home_team']} vs {row['away_team']}: {e}\")\n",
    "            summary_text = fallback_summary(row)\n",
    "            summaries.append(summary_text)\n",
    "            time.sleep(delay_per_call)\n",
    "            continue\n",
    "\n",
    "        success = False\n",
    "        for attempt in range(max_retries + 1):\n",
    "            try:\n",
    "                payload = {\n",
    "                    \"model\": model_name,\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    \"max_tokens\": 90,\n",
    "                    \"temperature\": 0.3,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"repetition_penalty\": 1.05,\n",
    "                    \"stop\": [\"\\n\\n\", \"Match:\", \"League:\", \"User:\", \"Assistant:\"]\n",
    "                }\n",
    "\n",
    "                response = requests.post(api_url, headers=headers, json=payload, timeout=30)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    \n",
    "                    # ✅ Correct key for /chat/completions\n",
    "                    content = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                    \n",
    "                    # Clean up: take only first 1–2 sentences\n",
    "                    sentences = [s.strip() for s in content.split('. ') if s.strip()]\n",
    "                    summary_text = '. '.join(sentences[:2]) + '.' if sentences else fallback_summary(row)\n",
    "                    \n",
    "                    success = True\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"❌ HTTP {response.status_code} on attempt {attempt + 1}: {response.text[:100]}...\")\n",
    "                    time.sleep(2 ** attempt)  # Exponential backoff\n",
    "\n",
    "            except KeyError as e:\n",
    "                print(f\"🔑 Parse error (missing key {e}) - retrying...\")\n",
    "                time.sleep(1.5)\n",
    "            except Exception as e:\n",
    "                if attempt >= max_retries:\n",
    "                    print(f\"🛑 Failed after retries: {row['home_team']} vs {row['away_team']} | Error: {e}\")\n",
    "                else:\n",
    "                    time.sleep(2 ** attempt)\n",
    "\n",
    "        if not success:\n",
    "            summary_text = fallback_summary(row)\n",
    "\n",
    "        # Final quality filter\n",
    "        if is_generic(summary_text):\n",
    "            summary_text = refine_with_fallback(row, summary_text)\n",
    "\n",
    "        summaries.append(summary_text)\n",
    "        time.sleep(delay_per_call)\n",
    "\n",
    "    # Add to DataFrame\n",
    "    result_df = odds_df.copy()\n",
    "    result_df['tip_summary'] = summaries\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0522869-dc28-416d-a278-02eebbc49ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = build_enhanced_prompt(df_enriched.iloc[0])\n",
    "\n",
    "payload = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": test_prompt}],\n",
    "    \"max_tokens\": 90,\n",
    "    \"temperature\": 0.3,\n",
    "    \"top_p\": 0.9,\n",
    "    \"repetition_penalty\": 1.05,\n",
    "    \"stop\": [\"\\n\\n\", \"Match:\", \"User:\", \"Assistant:\"]\n",
    "}\n",
    "\n",
    "resp = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "print(\"Status:\", resp.status_code)\n",
    "if resp.status_code == 200:\n",
    "    print(\"Success:\\n\", resp.json()[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "else:\n",
    "    print(\"Error:\\n\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de29973-ac0c-4c5c-a463-ea049266e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow\n",
    "df_tips = fetch_expert_tips_ml(odds_df, recent_results_df_all, strong_threshold=0.2)\n",
    "df_enriched = enrich_with_insights(df_tips)\n",
    "df_final = add_llm_summaries(df_enriched, delay_per_call=0.5)\n",
    "df_final['tip_source'] = df_final['strong_tip'].map({True: 'strong_ml', False: 'weak_ml'})\n",
    "cols = [\n",
    "    'home_team', 'away_team', 'league',\n",
    "    'home_odds', 'draw_odds', 'away_odds',\n",
    "    'home_win_prob', 'draw_prob', 'away_win_prob',\n",
    "    'expert_tip', 'strong_tip', 'tip_source',  # if you added ensemble earlier\n",
    "    'tip_summary'\n",
    "]\n",
    "\n",
    "display(df_final[cols].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8de941-43f7-4fb3-9a7f-3ce837ea843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove timezone info from all DataFrames before saving to Excel\n",
    "def remove_timezone_from_df(df):\n",
    "    \"\"\"Remove timezone info from datetime columns in a DataFrame\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return df\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            df[col] = df[col].dt.tz_localize(None)  # Remove timezone info\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4074da-b975-4845-9deb-039aa0f3b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File configuration\n",
    "TODAY = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "OUTPUT_FILE = f\"football_data_{TODAY}.xlsx\"\n",
    "\n",
    "# Create a dictionary of all DataFrames to clean\n",
    "dataframes_to_clean = {\n",
    "    \"Fixtures\": fixtures_df,\n",
    "    \"Odds\": odds_df,\n",
    "    \"Recent Results\": recent_results_df_all,\n",
    "    \"Expert Tips\": df_enriched,\n",
    "    \"LLM Summaries\": df_final\n",
    "}\n",
    "\n",
    "# Clean all DataFrames in one go using dictionary comprehension\n",
    "cleaned_dataframes = {\n",
    "    sheet_name: remove_timezone_from_df(df.copy()) \n",
    "    for sheet_name, df in dataframes_to_clean.items()\n",
    "}\n",
    "\n",
    "# Create main metadata DataFrame\n",
    "metadata = {\n",
    "    \"Generated On\": [datetime.now().replace(tzinfo=None)],\n",
    "    \"Leagues Included\": [\", \".join(all_leagues)],\n",
    "    \"Total Fixtures\": [len(fixtures_df)],\n",
    "    \"Total Odds\": [len(odds_df)],\n",
    "    \"Total Recent Results\": [len(recent_results_df_all)],\n",
    "    \"Total Matches with Tips\": [len(df_final)],\n",
    "    \"Total Matches with LLM Summaries\": [len(df_final)]\n",
    "}\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "\n",
    "# Create soccer keys DataFrame\n",
    "if not df_soccer.empty:\n",
    "    soccer_keys_list = [f\"{row['key']} ({row['title']})\" for _, row in df_soccer.iterrows()]\n",
    "else:\n",
    "    soccer_keys_list = [\"No soccer keys data\"]\n",
    "\n",
    "soccer_keys_df = pd.DataFrame({\n",
    "    \"Available Soccer Keys\": soccer_keys_list\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "with pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\") as writer:\n",
    "    # Write main DataFrames\n",
    "    for sheet_name, df_clean in cleaned_dataframes.items():\n",
    "        df_clean.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    \n",
    "    # Write metadata section\n",
    "    metadata_df.to_excel(writer, sheet_name=\"Metadata\", index=False)\n",
    "    \n",
    "    # Write soccer keys section with empty row separation\n",
    "    start_row = len(metadata_df) + 2  # +2 for header row and one empty row\n",
    "    soccer_keys_df.to_excel(writer, sheet_name=\"Metadata\", index=False, \n",
    "                          startrow=start_row, header=True)\n",
    "\n",
    "print(f\"All data saved successfully to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e37f39a2-57cf-4564-9633-ed5085922de4",
   "metadata": {},
   "source": [
    "Telegram Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce935a7-f3fd-49c0-8af2-e69f3fd3dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong tips within the next 48 hours\n",
    "def filter_strong_tips(df_final: pd.DataFrame, max_hours_ahead=48) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter strong ML tips where:\n",
    "    - tip_source == 'strong_ml'\n",
    "    - match has not started\n",
    "    - match starts within the next 2 days (48 hours)\n",
    "    Returns cleaned DataFrame with odds and formatted time.\n",
    "    \"\"\"\n",
    "    # Step 1: Filter strong tips\n",
    "    if df_final.empty:\n",
    "        return df_final\n",
    "\n",
    "    strong_mask = df_final['tip_source'] == 'strong_ml'\n",
    "    strong_tips_df = df_final[strong_mask].copy()\n",
    "    \n",
    "    if strong_tips_df.empty:\n",
    "        return strong_tips_df\n",
    "\n",
    "    # Ensure datetime column exists and is datetime type\n",
    "    if 'datetime_local' not in strong_tips_df.columns:\n",
    "        raise KeyError(\"Column 'datetime_local' not found in DataFrame.\")\n",
    "        \n",
    "    if not pd.api.types.is_datetime64_any_dtype(strong_tips_df['datetime_local']):\n",
    "        raise TypeError(\"Column 'datetime_local' must be a datetime type.\")\n",
    "\n",
    "    # Remove timezone if present (ensure naive)\n",
    "    if strong_tips_df['datetime_local'].dt.tz is not None:\n",
    "        print(\"Removing timezone info from datetime_local...\")\n",
    "        dt_local = strong_tips_df['datetime_local'].dt.tz_localize(None)\n",
    "    else:\n",
    "        dt_local = strong_tips_df['datetime_local']\n",
    "\n",
    "    # Use Africa/Nairobi as reference time context\n",
    "    try:\n",
    "        now_naive = pd.Timestamp.now(tz='Africa/Nairobi').tz_localize(None)\n",
    "    except Exception:\n",
    "        print(\"Warning: Fallback to system time.\")\n",
    "        now_naive = pd.Timestamp.now()\n",
    "\n",
    "    # Define time window: now to now + 2 days\n",
    "    two_days_ahead = now_naive + pd.Timedelta(days=2)\n",
    "\n",
    "    # Create mask: match hasn't started AND is within next 2 days\n",
    "    upcoming_mask = (dt_local > now_naive) & (dt_local <= two_days_ahead)\n",
    "    upcoming_tips_df = strong_tips_df[upcoming_mask].copy()\n",
    "\n",
    "    if upcoming_tips_df.empty:\n",
    "        return upcoming_tips_df\n",
    "\n",
    "    # Column mapping for output\n",
    "    column_mapping = {\n",
    "        'league': 'league',\n",
    "        'datetime_local': 'datetime_local',\n",
    "        'home_team': 'home',\n",
    "        'away_team': 'away',\n",
    "        'home_odds': 'home_odds',\n",
    "        'draw_odds': 'draw_odds',\n",
    "        'away_odds': 'away_odds',\n",
    "        'expert_tip': 'expert_tip',\n",
    "        'tip_summary': 'tip_summary'\n",
    "    }\n",
    "\n",
    "    missing_cols = [col for col in column_mapping.keys() if col not in upcoming_tips_df.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "    result = upcoming_tips_df[list(column_mapping.keys())].rename(columns=column_mapping)\n",
    "\n",
    "    # Format datetime as string for display\n",
    "    result['datetime_local'] = result['datetime_local'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859db17-4faa-4dbe-9b0c-85aafc94cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage message history\n",
    "def load_message_history(storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"Load message history from JSON file\"\"\"\n",
    "    try:\n",
    "        with open(storage_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return {}\n",
    "\n",
    "def save_message_history(history, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"Save message history to JSON file\"\"\"\n",
    "    with open(storage_file, 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "\n",
    "def track_message(chat_id, message_id, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"Track a message ID for a specific chat in persistent storage\"\"\"\n",
    "    history = load_message_history(storage_file)\n",
    "    \n",
    "    if str(chat_id) not in history:\n",
    "        history[str(chat_id)] = []\n",
    "    \n",
    "    # Add new message ID and keep only unique IDs\n",
    "    if message_id not in history[str(chat_id)]:\n",
    "        history[str(chat_id)].append(message_id)\n",
    "    \n",
    "    # Optional: Limit to last 200 messages per chat to avoid file bloat\n",
    "    history[str(chat_id)] = history[str(chat_id)][-200:]\n",
    "    \n",
    "    save_message_history(history, storage_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f738647e-d9bf-4beb-a232-81554edf23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bot/check_structure.py\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def check_structure():\n",
    "    print(\"🔍 Checking directory structure...\")\n",
    "    \n",
    "    # Current working directory\n",
    "    print(f\"📁 Current working directory: {os.getcwd()}\")\n",
    "    \n",
    "    # Where this script is located\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    print(f\"📁 Script directory: {script_dir}\")\n",
    "    \n",
    "    # List files in script directory\n",
    "    print(f\"📂 Files in bot directory:\")\n",
    "    for file in os.listdir(script_dir):\n",
    "        print(f\"   - {file}\")\n",
    "    \n",
    "    # Check if prediction_main.py exists\n",
    "    prediction_path = os.path.join(script_dir, \"prediction_main.py\")\n",
    "    print(f\"🔎 Looking for prediction_main.py at: {prediction_path}\")\n",
    "    print(f\"✅ File exists: {os.path.exists(prediction_path)}\")\n",
    "    \n",
    "    # Check Python path\n",
    "    print(f\"🐍 Python executable: {sys.executable}\")\n",
    "    print(f\"📦 Python path: {sys.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8afd36-53bd-46cd-8eea-4e720bc7e0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511d089-0ef0-4dc4-b221-5e7fccaeebcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7183f-c73d-43a2-86af-2ed8f44858ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send messages\n",
    "def send_telegram_message(message, chat_ids, bot_token, track_message_id=True, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"\n",
    "    Helper function to send a single Telegram message with optional tracking\n",
    "    \n",
    "    Parameters:\n",
    "    message (str): The message to send\n",
    "    chat_ids (list): List of chat IDs to send to\n",
    "    bot_token (str): Bot token\n",
    "    track_message_id (bool): Whether to track the message ID for later deletion\n",
    "    storage_file (str): Path to the JSON storage file\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if at least one message was sent successfully\n",
    "    \"\"\"\n",
    "    success_count = 0\n",
    "    \n",
    "    for chat_id in chat_ids:\n",
    "        try:\n",
    "            url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "            payload = {\n",
    "                'chat_id': chat_id,\n",
    "                'text': message,\n",
    "                'parse_mode': 'Markdown',\n",
    "                'disable_web_page_preview': True\n",
    "            }\n",
    "            \n",
    "            response = requests.post(url, data=payload)\n",
    "            if response.status_code == 200:\n",
    "                success_count += 1\n",
    "                \n",
    "                # Track the message ID if requested\n",
    "                if track_message_id:\n",
    "                    message_id = response.json()['result']['message_id']\n",
    "                    track_message(chat_id, message_id, storage_file)\n",
    "                    \n",
    "            else:\n",
    "                print(f\"❌ Failed to send message to {chat_id}: {response.text}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error sending message to {chat_id}: {e}\")\n",
    "    \n",
    "    return success_count > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62384f0-9a71-4e42-a090-17a2e58ad152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send strong tips\n",
    "def send_strong_tips_telegram_multiple_users(strong_tips_df, chat_ids, bot_token, track_messages=True, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"\n",
    "    Send strong tips to multiple Telegram users with message chunking and tracking\n",
    "    \n",
    "    Parameters:\n",
    "    strong_tips_df (DataFrame): DataFrame with strong tips data\n",
    "    chat_ids (list): List of chat IDs to send to\n",
    "    bot_token (str): Bot token\n",
    "    track_messages (bool): Whether to track message IDs for later deletion\n",
    "    storage_file (str): Path to the JSON storage file\n",
    "    \n",
    "    Returns:\n",
    "    int: Total number of successful message sends\n",
    "    \"\"\"\n",
    "    if strong_tips_df.empty:\n",
    "        message = \"⚽ No strong tips found today! ⚽\"\n",
    "        send_count = 1 if send_telegram_message(message, chat_ids, bot_token, track_messages, storage_file) else 0\n",
    "        return send_count\n",
    "    \n",
    "    total_success_count = 0\n",
    "    \n",
    "    for chat_id in chat_ids:\n",
    "        chat_success_count = 0\n",
    "        \n",
    "        try:\n",
    "            # Create message header\n",
    "            header = f\"⚽ *STRONG BETTING TIPS* ⚽\\n\\n\"\n",
    "            header += f\"Found {len(strong_tips_df)} matches with strong tips:\\n\\n\"\n",
    "            \n",
    "            # ✅ Add payment information\n",
    "            header += \"🔐 *For advanced modelling tips, support via MPESA:* \\n\"\n",
    "            header += \"📌 *TILL: 9105695*\\n\"\n",
    "            header += \"📱 *Mobile:* +254722586447\\n\\n\"  # Replace 07XXXXXX with actual number\n",
    "            header += \"Thank you for your support! 💙\\n\\n\"\n",
    "            \n",
    "            # Send header first\n",
    "            if send_telegram_message(header, [chat_id], bot_token, track_messages, storage_file):\n",
    "                chat_success_count += 1\n",
    "            \n",
    "            # Send each match as separate message\n",
    "            for _, row in strong_tips_df.iterrows():\n",
    "                match_message = f\"🏆 *{row['league']}*\\n\"\n",
    "                match_message += f\"⏰ {row['datetime_local']}\\n\"\n",
    "                match_message += f\"🏠 {row['home']} vs {row['away']}\\n\"\n",
    "                \n",
    "                # ✅ Correctly show decimal odds\n",
    "                match_message += f\"🔢 Odds: {row['home_odds']:.2f} | {row['draw_odds']:.2f} | {row['away_odds']:.2f}\\n\"\n",
    "                \n",
    "                # Show expert tip\n",
    "                tip_emoji = \"🟢 HOME\" if row['expert_tip'] == 'home' else \\\n",
    "                           (\"🟡 DRAW\" if row['expert_tip'] == 'draw' else \"🔵 AWAY\")\n",
    "                match_message += f\"💡 Tip: {tip_emoji} ({row['expert_tip'].upper()})\\n\"\n",
    "                \n",
    "                # Truncate summary if too long\n",
    "                summary = str(row['tip_summary'])\n",
    "                if len(summary) > 200:\n",
    "                    match_message += f\"📝 Summary: {summary[:200]}...\\n\"\n",
    "                else:\n",
    "                    match_message += f\"📝 Summary: {summary}\\n\"\n",
    "                \n",
    "                match_message += \"─\" * 30\n",
    "                \n",
    "                # Send individual match message\n",
    "                if send_telegram_message(match_message, [chat_id], bot_token, track_messages, storage_file):\n",
    "                    chat_success_count += 1\n",
    "            \n",
    "            print(f\"✅ {chat_success_count} messages sent to chat ID: {chat_id}\")\n",
    "            total_success_count += chat_success_count\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error sending to {chat_id}: {e}\")\n",
    "    \n",
    "    print(f\"\\n📊 Summary: Total messages sent: {total_success_count}\")\n",
    "    return total_success_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee750507-f597-433e-8ff3-9226c62097e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get chat IDS\n",
    "def get_chat_ids(bot_token):\n",
    "    \"\"\"Get all chat IDs that have interacted with your bot\"\"\"\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/getUpdates\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            chat_ids = set()\n",
    "            \n",
    "            for update in data.get('result', []):\n",
    "                if 'message' in update and 'chat' in update['message']:\n",
    "                    chat_ids.add(update['message']['chat']['id'])\n",
    "            \n",
    "            print(\"Found chat IDs:\", list(chat_ids))\n",
    "            return list(chat_ids)\n",
    "        else:\n",
    "            print(\"Error getting updates:\", response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return []\n",
    "\n",
    "def clear_bot_messages(chat_id=None, bot_token=BOT_TOKEN, storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"\n",
    "    Clear all tracked bot messages for a specific chat or all chats.\n",
    "    \n",
    "    Parameters:\n",
    "    chat_id (int/str): Specific chat ID to clear. If None, clears all chats.\n",
    "    bot_token (str): Bot token to use for deletion\n",
    "    storage_file (str): Path to the JSON storage file\n",
    "    \"\"\"\n",
    "    history = load_message_history(storage_file)\n",
    "    \n",
    "    if not history:\n",
    "        print(\"No message history found to clear.\")\n",
    "        return 0\n",
    "    \n",
    "    chats_to_clear = [str(chat_id)] if chat_id else list(history.keys())\n",
    "    total_deleted = 0\n",
    "    \n",
    "    for current_chat_id in chats_to_clear:\n",
    "        if current_chat_id not in history:\n",
    "            print(f\"Chat ID {current_chat_id} not found in history.\")\n",
    "            continue\n",
    "            \n",
    "        message_ids = history[current_chat_id]\n",
    "        deleted_in_chat = 0\n",
    "        \n",
    "        print(f\"\\nClearing {len(message_ids)} messages in chat {current_chat_id}...\")\n",
    "        \n",
    "        for msg_id in message_ids:\n",
    "            url = f\"https://api.telegram.org/bot{bot_token}/deleteMessage\"\n",
    "            payload = {\n",
    "                'chat_id': current_chat_id,\n",
    "                'message_id': msg_id\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.post(url, data=payload)\n",
    "                if response.status_code == 200:\n",
    "                    deleted_in_chat += 1\n",
    "                    total_deleted += 1\n",
    "                    print(f\"✓ Deleted message {msg_id}\")\n",
    "                else:\n",
    "                    print(f\"✗ Failed to delete {msg_id}: {response.text}\")\n",
    "                \n",
    "                # Add a small delay to avoid hitting rate limits\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error deleting {msg_id}: {e}\")\n",
    "        \n",
    "        # Clear the history for this chat after successful deletion\n",
    "        history[current_chat_id] = []\n",
    "        print(f\"Cleared {deleted_in_chat} messages from chat {current_chat_id}\")\n",
    "    \n",
    "    # Save the updated history (with cleared chats)\n",
    "    save_message_history(history, storage_file)\n",
    "    print(f\"\\n🎉 Total messages deleted: {total_deleted}\")\n",
    "    return total_deleted\n",
    "\n",
    "def show_message_stats(storage_file=JSON_STORAGE_FILE):\n",
    "    \"\"\"Show statistics about tracked messages\"\"\"\n",
    "    history = load_message_history(storage_file)\n",
    "    total_messages = 0\n",
    "    \n",
    "    print(\"📊 Message Tracking Statistics:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for chat_id, messages in history.items():\n",
    "        print(f\"Chat {chat_id}: {len(messages)} messages\")\n",
    "        total_messages += len(messages)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total chats: {len(history)}\")\n",
    "    print(f\"Total messages: {total_messages}\")\n",
    "    return len(history), total_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286dcf6-0c43-4cd6-941a-a23f5042b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting chat IDs...\")\n",
    "chat_ids = get_chat_ids(BOT_TOKEN)\n",
    "\n",
    "# Print the number of participants\n",
    "if chat_ids:\n",
    "    print(f\"✅ Number of participants: {len(chat_ids)}\")\n",
    "else:\n",
    "    print(\"❌ No participants found. Chat ID list is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debef94a-95ad-4f01-8d60-245092eee155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the strong tips\n",
    "df_final = remove_timezone_from_df(df_final) \n",
    "strong_tips_filtered = filter_strong_tips(df_final, max_hours_ahead=48)  # 2-day lookahead\n",
    "print(\"\\nSending strong tips with tracking...\")\n",
    "send_count = send_strong_tips_telegram_multiple_users(\n",
    "    strong_tips_filtered, \n",
    "    chat_ids, \n",
    "    BOT_TOKEN,\n",
    "    track_messages=True  # Set to False if you don't want to track these messages\n",
    ")\n",
    "print(f\"Sent {send_count} messages\")\n",
    "\n",
    "# Show current message statistics\n",
    "print(\"\\nCurrent stats:\")\n",
    "show_message_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190af9a0-df2b-4a4b-a6e0-65271e567d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing messages\n",
    "# Clear messages from a specific chat\n",
    "# clear_bot_messages(chat_id=123456789, bot_token=BOT_TOKEN)\n",
    "\n",
    "# Clear messages from ALL chats (use with caution!)\n",
    "#print(\"\\nClearing all messages...\")\n",
    "#deleted_count = clear_bot_messages(bot_token=BOT_TOKEN)\n",
    "#print(f\"Deleted {deleted_count} messages\")\n",
    "\n",
    "# Send a message without tracking (for one-time notifications)\n",
    "# send_telegram_message(\"This message won't be tracked\", chat_ids, BOT_TOKEN, track_message_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d40f6-9516-40c8-9d03-43dccd845de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
